{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d71177e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dk/mxqr91nj7135zkb7ptp3mq5c0000gn/T/ipykernel_13106/3166594014.py:16: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  mlp.style.use('seaborn')\n"
     ]
    }
   ],
   "source": [
    "# 1. Import libraries:\n",
    "%matplotlib inline\n",
    "import os\n",
    "import quandl\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.optimize as spo\n",
    "from scipy.stats import kurtosis, skew\n",
    "import seaborn as sns\n",
    "from financial_data import *\n",
    "import tensorflow as tf\n",
    "mlp.style.use('seaborn')\n",
    "quandl.save_key('HtwBLPt3k37yZHTvy15K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66ead6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Saint Paul, Minnesota</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>91142</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol     Security             GICS Sector               GICS Sub-Industry  \\\n",
       "0    MMM           3M             Industrials        Industrial Conglomerates   \n",
       "1    AOS  A. O. Smith             Industrials               Building Products   \n",
       "2    ABT       Abbott             Health Care           Health Care Equipment   \n",
       "3   ABBV       AbbVie             Health Care                 Pharmaceuticals   \n",
       "4    ACN    Accenture  Information Technology  IT Consulting & Other Services   \n",
       "\n",
       "     Headquarters Location  Date added      CIK      Founded  \n",
       "0    Saint Paul, Minnesota  1957-03-04    66740         1902  \n",
       "1     Milwaukee, Wisconsin  2017-07-26    91142         1916  \n",
       "2  North Chicago, Illinois  1957-03-04     1800         1888  \n",
       "3  North Chicago, Illinois  2012-12-31  1551152  2013 (1888)  \n",
       "4          Dublin, Ireland  2011-07-06  1467373         1989  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "sp500 = pd.read_html(sp_url, header=0)[0]\n",
    "sp500.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8f137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of stocks in the universe is: 243\n"
     ]
    }
   ],
   "source": [
    "# Correct invalid dates:\n",
    "sp500.loc[sp500[sp500['Date added']=='1983-11-30 (1957-03-04)'].index,'Date added'] = '1983-11-30'\n",
    "sp500.loc[sp500[sp500['Date added']=='2001?'].index,'Date added'] = '2001-01-01'\n",
    "# Filter firms that entered the index after December 2015:\n",
    "sp500['Date added'] = pd.to_datetime(sp500['Date added'],format='%Y-%m-%d')\n",
    "sp500 = sp500[sp500['Date added']<'2007-01-01']\n",
    "print(\"The number of stocks in the universe is:\", sp500.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2da63c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DIS', 'BIIB', 'GILD', 'ETR', 'PEP', 'NVDA', 'NI', 'BBWI', 'SWK', 'CBRE']\n"
     ]
    }
   ],
   "source": [
    "n_stocks = 10\n",
    "np.random.seed(1792)\n",
    "universe_tickers = sp500['Symbol'].unique()\n",
    "tickers = list(np.random.choice(universe_tickers,replace=False,size=n_stocks))\n",
    "print(tickers)\n",
    "# sp500[sp500['Symbol'].isin(portfolio_tickers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1573d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  10 of 10 completed\n",
      "            Adj Close                                                \\\n",
      "                 BBWI        BIIB       CBRE        DIS         ETR   \n",
      "Date                                                                  \n",
      "2007-01-03  10.077240   49.330002  33.650002  28.317095   46.684532   \n",
      "2007-01-04   9.317529   49.750000  33.340000  28.540646   47.236824   \n",
      "2007-01-05   9.310719   49.759998  33.099998  28.308819   46.071968   \n",
      "2007-01-08   9.130162   50.020000  33.220001  28.565489   45.725513   \n",
      "2007-01-09   9.266431   49.500000  33.970001  28.524096   45.695408   \n",
      "...               ...         ...        ...        ...         ...   \n",
      "2022-12-23  41.287590  279.160004  76.669998  88.010002  109.924477   \n",
      "2022-12-27  41.297436  274.769989  76.489998  86.370003  111.164909   \n",
      "2022-12-28  40.116104  274.040009  75.410004  84.169998  109.478691   \n",
      "2022-12-29  41.002102  276.000000  77.550003  87.180000  110.564072   \n",
      "2022-12-30  41.484478  276.920013  76.959999  86.879997  109.023216   \n",
      "\n",
      "                                                                     ...  \\\n",
      "                 GILD         NI        NVDA         PEP        SWK  ...   \n",
      "Date                                                                 ...   \n",
      "2007-01-03  11.958691   4.979854    5.516786   38.873482  34.064182  ...   \n",
      "2007-01-04  12.155637   4.961387    5.490792   39.139996  34.278854  ...   \n",
      "2007-01-05  12.159423   4.836224    5.146760   39.016037  34.144657  ...   \n",
      "2007-01-08  12.163210   4.828016    5.184986   39.102821  34.017239  ...   \n",
      "2007-01-09  12.310920   4.842379    5.084071   39.263969  34.634388  ...   \n",
      "...               ...        ...         ...         ...        ...  ...   \n",
      "2022-12-23  83.147980  26.970551  152.005920  178.524826  71.870193  ...   \n",
      "2022-12-27  83.403076  27.058151  141.159790  179.318237  72.327049  ...   \n",
      "2022-12-28  82.971390  26.814819  140.310074  178.025269  70.159462  ...   \n",
      "2022-12-29  83.648346  27.097084  145.978073  178.250565  73.785049  ...   \n",
      "2022-12-30  84.227188  26.688292  146.088028  176.957626  73.017166  ...   \n",
      "\n",
      "                  Low                                                \\\n",
      "                 BBWI        BIIB       CBRE        DIS         ETR   \n",
      "Date                                                                  \n",
      "2007-01-03  23.540825   48.200001  33.139999  33.531136   92.089996   \n",
      "2007-01-04  21.891672   48.880001  33.099998  33.708706   92.599998   \n",
      "2007-01-05  21.147940   49.509998  32.799999  33.531136   91.279999   \n",
      "2007-01-08  21.471302   48.910000  32.500000  33.610054   90.870003   \n",
      "2007-01-09  21.827002   49.299999  33.060001  33.491676   90.540001   \n",
      "...               ...         ...        ...        ...         ...   \n",
      "2022-12-23  40.150002  276.070007  75.150002  85.769997  112.339996   \n",
      "2022-12-27  41.810001  273.380005  76.099998  85.959999  113.190002   \n",
      "2022-12-28  40.630001  272.640015  75.379997  84.070000  112.930000   \n",
      "2022-12-29  41.180000  274.299988  75.769997  84.970001  112.500000   \n",
      "2022-12-30  40.880001  272.200012  76.089996  85.230003  111.489998   \n",
      "\n",
      "                                                                     \n",
      "                 GILD         NI        NVDA         PEP        SWK  \n",
      "Date                                                                 \n",
      "2007-01-03  15.480000   9.469548    5.798333   62.450001  50.049999  \n",
      "2007-01-04  15.617500   9.469548    5.838333   62.500000  50.259998  \n",
      "2007-01-05  15.962500   9.229862    5.570000   62.700001  50.590000  \n",
      "2007-01-08  15.877500   9.182711    5.533333   62.860001  49.950001  \n",
      "2007-01-09  16.129999   9.210216    5.535000   63.009998  50.680000  \n",
      "...               ...        ...         ...         ...        ...  \n",
      "2022-12-23  84.279999  27.330000  148.830002  180.449997  72.599998  \n",
      "2022-12-27  84.690002  27.549999  140.559998  182.270004  73.250000  \n",
      "2022-12-28  84.449997  27.520000  138.839996  181.639999  72.160004  \n",
      "2022-12-29  84.610001  27.639999  142.270004  181.889999  72.769997  \n",
      "2022-12-30  84.779999  27.230000  142.330002  179.289993  74.330002  \n",
      "\n",
      "[4028 rows x 50 columns]\n",
      "the dataframe before the columns were renamed\n",
      "MultiIndex([('Adj Close', 'BBWI'),\n",
      "            ('Adj Close', 'BIIB'),\n",
      "            ('Adj Close', 'CBRE'),\n",
      "            ('Adj Close',  'DIS'),\n",
      "            ('Adj Close',  'ETR'),\n",
      "            ('Adj Close', 'GILD'),\n",
      "            ('Adj Close',   'NI'),\n",
      "            ('Adj Close', 'NVDA'),\n",
      "            ('Adj Close',  'PEP'),\n",
      "            ('Adj Close',  'SWK'),\n",
      "            (   'Volume', 'BBWI'),\n",
      "            (   'Volume', 'BIIB'),\n",
      "            (   'Volume', 'CBRE'),\n",
      "            (   'Volume',  'DIS'),\n",
      "            (   'Volume',  'ETR'),\n",
      "            (   'Volume', 'GILD'),\n",
      "            (   'Volume',   'NI'),\n",
      "            (   'Volume', 'NVDA'),\n",
      "            (   'Volume',  'PEP'),\n",
      "            (   'Volume',  'SWK'),\n",
      "            (     'Open', 'BBWI'),\n",
      "            (     'Open', 'BIIB'),\n",
      "            (     'Open', 'CBRE'),\n",
      "            (     'Open',  'DIS'),\n",
      "            (     'Open',  'ETR'),\n",
      "            (     'Open', 'GILD'),\n",
      "            (     'Open',   'NI'),\n",
      "            (     'Open', 'NVDA'),\n",
      "            (     'Open',  'PEP'),\n",
      "            (     'Open',  'SWK'),\n",
      "            (     'High', 'BBWI'),\n",
      "            (     'High', 'BIIB'),\n",
      "            (     'High', 'CBRE'),\n",
      "            (     'High',  'DIS'),\n",
      "            (     'High',  'ETR'),\n",
      "            (     'High', 'GILD'),\n",
      "            (     'High',   'NI'),\n",
      "            (     'High', 'NVDA'),\n",
      "            (     'High',  'PEP'),\n",
      "            (     'High',  'SWK'),\n",
      "            (      'Low', 'BBWI'),\n",
      "            (      'Low', 'BIIB'),\n",
      "            (      'Low', 'CBRE'),\n",
      "            (      'Low',  'DIS'),\n",
      "            (      'Low',  'ETR'),\n",
      "            (      'Low', 'GILD'),\n",
      "            (      'Low',   'NI'),\n",
      "            (      'Low', 'NVDA'),\n",
      "            (      'Low',  'PEP'),\n",
      "            (      'Low',  'SWK')],\n",
      "           )\n",
      "Index(['Adj Close_BBWI', 'Adj Close_BIIB', 'Adj Close_CBRE', 'Adj Close_DIS',\n",
      "       'Adj Close_ETR', 'Adj Close_GILD', 'Adj Close_NI', 'Adj Close_NVDA',\n",
      "       'Adj Close_PEP', 'Adj Close_SWK', 'Volume_BBWI', 'Volume_BIIB',\n",
      "       'Volume_CBRE', 'Volume_DIS', 'Volume_ETR', 'Volume_GILD', 'Volume_NI',\n",
      "       'Volume_NVDA', 'Volume_PEP', 'Volume_SWK', 'Open_BBWI', 'Open_BIIB',\n",
      "       'Open_CBRE', 'Open_DIS', 'Open_ETR', 'Open_GILD', 'Open_NI',\n",
      "       'Open_NVDA', 'Open_PEP', 'Open_SWK', 'High_BBWI', 'High_BIIB',\n",
      "       'High_CBRE', 'High_DIS', 'High_ETR', 'High_GILD', 'High_NI',\n",
      "       'High_NVDA', 'High_PEP', 'High_SWK', 'Low_BBWI', 'Low_BIIB', 'Low_CBRE',\n",
      "       'Low_DIS', 'Low_ETR', 'Low_GILD', 'Low_NI', 'Low_NVDA', 'Low_PEP',\n",
      "       'Low_SWK'],\n",
      "      dtype='object')\n",
      "the dataframe after the columns have been renamed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_BBWI</th>\n",
       "      <th>Close_BIIB</th>\n",
       "      <th>Close_CBRE</th>\n",
       "      <th>Close_DIS</th>\n",
       "      <th>Close_ETR</th>\n",
       "      <th>Close_GILD</th>\n",
       "      <th>Close_NI</th>\n",
       "      <th>Close_NVDA</th>\n",
       "      <th>Close_PEP</th>\n",
       "      <th>Close_SWK</th>\n",
       "      <th>...</th>\n",
       "      <th>Low_BBWI</th>\n",
       "      <th>Low_BIIB</th>\n",
       "      <th>Low_CBRE</th>\n",
       "      <th>Low_DIS</th>\n",
       "      <th>Low_ETR</th>\n",
       "      <th>Low_GILD</th>\n",
       "      <th>Low_NI</th>\n",
       "      <th>Low_NVDA</th>\n",
       "      <th>Low_PEP</th>\n",
       "      <th>Low_SWK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-03</th>\n",
       "      <td>10.077240</td>\n",
       "      <td>49.330002</td>\n",
       "      <td>33.650002</td>\n",
       "      <td>28.317095</td>\n",
       "      <td>46.684532</td>\n",
       "      <td>11.958691</td>\n",
       "      <td>4.979854</td>\n",
       "      <td>5.516786</td>\n",
       "      <td>38.873482</td>\n",
       "      <td>34.064182</td>\n",
       "      <td>...</td>\n",
       "      <td>23.540825</td>\n",
       "      <td>48.200001</td>\n",
       "      <td>33.139999</td>\n",
       "      <td>33.531136</td>\n",
       "      <td>92.089996</td>\n",
       "      <td>15.480000</td>\n",
       "      <td>9.469548</td>\n",
       "      <td>5.798333</td>\n",
       "      <td>62.450001</td>\n",
       "      <td>50.049999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>9.317529</td>\n",
       "      <td>49.750000</td>\n",
       "      <td>33.340000</td>\n",
       "      <td>28.540646</td>\n",
       "      <td>47.236824</td>\n",
       "      <td>12.155637</td>\n",
       "      <td>4.961387</td>\n",
       "      <td>5.490792</td>\n",
       "      <td>39.139996</td>\n",
       "      <td>34.278854</td>\n",
       "      <td>...</td>\n",
       "      <td>21.891672</td>\n",
       "      <td>48.880001</td>\n",
       "      <td>33.099998</td>\n",
       "      <td>33.708706</td>\n",
       "      <td>92.599998</td>\n",
       "      <td>15.617500</td>\n",
       "      <td>9.469548</td>\n",
       "      <td>5.838333</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>50.259998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>9.310719</td>\n",
       "      <td>49.759998</td>\n",
       "      <td>33.099998</td>\n",
       "      <td>28.308819</td>\n",
       "      <td>46.071968</td>\n",
       "      <td>12.159423</td>\n",
       "      <td>4.836224</td>\n",
       "      <td>5.146760</td>\n",
       "      <td>39.016037</td>\n",
       "      <td>34.144657</td>\n",
       "      <td>...</td>\n",
       "      <td>21.147940</td>\n",
       "      <td>49.509998</td>\n",
       "      <td>32.799999</td>\n",
       "      <td>33.531136</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>15.962500</td>\n",
       "      <td>9.229862</td>\n",
       "      <td>5.570000</td>\n",
       "      <td>62.700001</td>\n",
       "      <td>50.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-08</th>\n",
       "      <td>9.130162</td>\n",
       "      <td>50.020000</td>\n",
       "      <td>33.220001</td>\n",
       "      <td>28.565489</td>\n",
       "      <td>45.725513</td>\n",
       "      <td>12.163210</td>\n",
       "      <td>4.828016</td>\n",
       "      <td>5.184986</td>\n",
       "      <td>39.102821</td>\n",
       "      <td>34.017239</td>\n",
       "      <td>...</td>\n",
       "      <td>21.471302</td>\n",
       "      <td>48.910000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>33.610054</td>\n",
       "      <td>90.870003</td>\n",
       "      <td>15.877500</td>\n",
       "      <td>9.182711</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>49.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-09</th>\n",
       "      <td>9.266431</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>33.970001</td>\n",
       "      <td>28.524096</td>\n",
       "      <td>45.695408</td>\n",
       "      <td>12.310920</td>\n",
       "      <td>4.842379</td>\n",
       "      <td>5.084071</td>\n",
       "      <td>39.263969</td>\n",
       "      <td>34.634388</td>\n",
       "      <td>...</td>\n",
       "      <td>21.827002</td>\n",
       "      <td>49.299999</td>\n",
       "      <td>33.060001</td>\n",
       "      <td>33.491676</td>\n",
       "      <td>90.540001</td>\n",
       "      <td>16.129999</td>\n",
       "      <td>9.210216</td>\n",
       "      <td>5.535000</td>\n",
       "      <td>63.009998</td>\n",
       "      <td>50.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>41.287590</td>\n",
       "      <td>279.160004</td>\n",
       "      <td>76.669998</td>\n",
       "      <td>88.010002</td>\n",
       "      <td>109.924477</td>\n",
       "      <td>83.147980</td>\n",
       "      <td>26.970551</td>\n",
       "      <td>152.005920</td>\n",
       "      <td>178.524826</td>\n",
       "      <td>71.870193</td>\n",
       "      <td>...</td>\n",
       "      <td>40.150002</td>\n",
       "      <td>276.070007</td>\n",
       "      <td>75.150002</td>\n",
       "      <td>85.769997</td>\n",
       "      <td>112.339996</td>\n",
       "      <td>84.279999</td>\n",
       "      <td>27.330000</td>\n",
       "      <td>148.830002</td>\n",
       "      <td>180.449997</td>\n",
       "      <td>72.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>41.297436</td>\n",
       "      <td>274.769989</td>\n",
       "      <td>76.489998</td>\n",
       "      <td>86.370003</td>\n",
       "      <td>111.164909</td>\n",
       "      <td>83.403076</td>\n",
       "      <td>27.058151</td>\n",
       "      <td>141.159790</td>\n",
       "      <td>179.318237</td>\n",
       "      <td>72.327049</td>\n",
       "      <td>...</td>\n",
       "      <td>41.810001</td>\n",
       "      <td>273.380005</td>\n",
       "      <td>76.099998</td>\n",
       "      <td>85.959999</td>\n",
       "      <td>113.190002</td>\n",
       "      <td>84.690002</td>\n",
       "      <td>27.549999</td>\n",
       "      <td>140.559998</td>\n",
       "      <td>182.270004</td>\n",
       "      <td>73.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>40.116104</td>\n",
       "      <td>274.040009</td>\n",
       "      <td>75.410004</td>\n",
       "      <td>84.169998</td>\n",
       "      <td>109.478691</td>\n",
       "      <td>82.971390</td>\n",
       "      <td>26.814819</td>\n",
       "      <td>140.310074</td>\n",
       "      <td>178.025269</td>\n",
       "      <td>70.159462</td>\n",
       "      <td>...</td>\n",
       "      <td>40.630001</td>\n",
       "      <td>272.640015</td>\n",
       "      <td>75.379997</td>\n",
       "      <td>84.070000</td>\n",
       "      <td>112.930000</td>\n",
       "      <td>84.449997</td>\n",
       "      <td>27.520000</td>\n",
       "      <td>138.839996</td>\n",
       "      <td>181.639999</td>\n",
       "      <td>72.160004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>41.002102</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>77.550003</td>\n",
       "      <td>87.180000</td>\n",
       "      <td>110.564072</td>\n",
       "      <td>83.648346</td>\n",
       "      <td>27.097084</td>\n",
       "      <td>145.978073</td>\n",
       "      <td>178.250565</td>\n",
       "      <td>73.785049</td>\n",
       "      <td>...</td>\n",
       "      <td>41.180000</td>\n",
       "      <td>274.299988</td>\n",
       "      <td>75.769997</td>\n",
       "      <td>84.970001</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>84.610001</td>\n",
       "      <td>27.639999</td>\n",
       "      <td>142.270004</td>\n",
       "      <td>181.889999</td>\n",
       "      <td>72.769997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>41.484478</td>\n",
       "      <td>276.920013</td>\n",
       "      <td>76.959999</td>\n",
       "      <td>86.879997</td>\n",
       "      <td>109.023216</td>\n",
       "      <td>84.227188</td>\n",
       "      <td>26.688292</td>\n",
       "      <td>146.088028</td>\n",
       "      <td>176.957626</td>\n",
       "      <td>73.017166</td>\n",
       "      <td>...</td>\n",
       "      <td>40.880001</td>\n",
       "      <td>272.200012</td>\n",
       "      <td>76.089996</td>\n",
       "      <td>85.230003</td>\n",
       "      <td>111.489998</td>\n",
       "      <td>84.779999</td>\n",
       "      <td>27.230000</td>\n",
       "      <td>142.330002</td>\n",
       "      <td>179.289993</td>\n",
       "      <td>74.330002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4028 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close_BBWI  Close_BIIB  Close_CBRE  Close_DIS   Close_ETR  \\\n",
       "Date                                                                    \n",
       "2007-01-03   10.077240   49.330002   33.650002  28.317095   46.684532   \n",
       "2007-01-04    9.317529   49.750000   33.340000  28.540646   47.236824   \n",
       "2007-01-05    9.310719   49.759998   33.099998  28.308819   46.071968   \n",
       "2007-01-08    9.130162   50.020000   33.220001  28.565489   45.725513   \n",
       "2007-01-09    9.266431   49.500000   33.970001  28.524096   45.695408   \n",
       "...                ...         ...         ...        ...         ...   \n",
       "2022-12-23   41.287590  279.160004   76.669998  88.010002  109.924477   \n",
       "2022-12-27   41.297436  274.769989   76.489998  86.370003  111.164909   \n",
       "2022-12-28   40.116104  274.040009   75.410004  84.169998  109.478691   \n",
       "2022-12-29   41.002102  276.000000   77.550003  87.180000  110.564072   \n",
       "2022-12-30   41.484478  276.920013   76.959999  86.879997  109.023216   \n",
       "\n",
       "            Close_GILD   Close_NI  Close_NVDA   Close_PEP  Close_SWK  ...  \\\n",
       "Date                                                                  ...   \n",
       "2007-01-03   11.958691   4.979854    5.516786   38.873482  34.064182  ...   \n",
       "2007-01-04   12.155637   4.961387    5.490792   39.139996  34.278854  ...   \n",
       "2007-01-05   12.159423   4.836224    5.146760   39.016037  34.144657  ...   \n",
       "2007-01-08   12.163210   4.828016    5.184986   39.102821  34.017239  ...   \n",
       "2007-01-09   12.310920   4.842379    5.084071   39.263969  34.634388  ...   \n",
       "...                ...        ...         ...         ...        ...  ...   \n",
       "2022-12-23   83.147980  26.970551  152.005920  178.524826  71.870193  ...   \n",
       "2022-12-27   83.403076  27.058151  141.159790  179.318237  72.327049  ...   \n",
       "2022-12-28   82.971390  26.814819  140.310074  178.025269  70.159462  ...   \n",
       "2022-12-29   83.648346  27.097084  145.978073  178.250565  73.785049  ...   \n",
       "2022-12-30   84.227188  26.688292  146.088028  176.957626  73.017166  ...   \n",
       "\n",
       "             Low_BBWI    Low_BIIB   Low_CBRE    Low_DIS     Low_ETR  \\\n",
       "Date                                                                  \n",
       "2007-01-03  23.540825   48.200001  33.139999  33.531136   92.089996   \n",
       "2007-01-04  21.891672   48.880001  33.099998  33.708706   92.599998   \n",
       "2007-01-05  21.147940   49.509998  32.799999  33.531136   91.279999   \n",
       "2007-01-08  21.471302   48.910000  32.500000  33.610054   90.870003   \n",
       "2007-01-09  21.827002   49.299999  33.060001  33.491676   90.540001   \n",
       "...               ...         ...        ...        ...         ...   \n",
       "2022-12-23  40.150002  276.070007  75.150002  85.769997  112.339996   \n",
       "2022-12-27  41.810001  273.380005  76.099998  85.959999  113.190002   \n",
       "2022-12-28  40.630001  272.640015  75.379997  84.070000  112.930000   \n",
       "2022-12-29  41.180000  274.299988  75.769997  84.970001  112.500000   \n",
       "2022-12-30  40.880001  272.200012  76.089996  85.230003  111.489998   \n",
       "\n",
       "             Low_GILD     Low_NI    Low_NVDA     Low_PEP    Low_SWK  \n",
       "Date                                                                 \n",
       "2007-01-03  15.480000   9.469548    5.798333   62.450001  50.049999  \n",
       "2007-01-04  15.617500   9.469548    5.838333   62.500000  50.259998  \n",
       "2007-01-05  15.962500   9.229862    5.570000   62.700001  50.590000  \n",
       "2007-01-08  15.877500   9.182711    5.533333   62.860001  49.950001  \n",
       "2007-01-09  16.129999   9.210216    5.535000   63.009998  50.680000  \n",
       "...               ...        ...         ...         ...        ...  \n",
       "2022-12-23  84.279999  27.330000  148.830002  180.449997  72.599998  \n",
       "2022-12-27  84.690002  27.549999  140.559998  182.270004  73.250000  \n",
       "2022-12-28  84.449997  27.520000  138.839996  181.639999  72.160004  \n",
       "2022-12-29  84.610001  27.639999  142.270004  181.889999  72.769997  \n",
       "2022-12-30  84.779999  27.230000  142.330002  179.289993  74.330002  \n",
       "\n",
       "[4028 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tickers = ['AAPL', 'GOOGL', 'MSFT','SPY']\n",
    "# start_date='2007-01-01'\n",
    "# end_date='2022-12-31'\n",
    "# columns = ['Adj Close', 'Volume']\n",
    "# # Download data\n",
    "# data = yf.download(tickers, start=start_date, end=end_date)[columns]\n",
    "\n",
    "# # 'data' will be a Pandas DataFrame containing the historical data for the specified tickers\n",
    "# print(data)\n",
    "\n",
    "\n",
    "def download_data(tickers, start_date, end_date, columns):\n",
    "    data = yf.download(tickers, start=start_date, end=end_date)\n",
    "    data=data[columns]\n",
    "    return data\n",
    "\n",
    "# Define the tickers, start date, end date, and columns you want to download\n",
    "# tickers = ['AAPL', 'GOOGL', 'MSFT']\n",
    "start_date = '2007-01-01'\n",
    "end_date = '2022-12-31'\n",
    "columns = [ 'Adj Close', 'Volume','Open','High','Low']\n",
    "\n",
    "# Download the data\n",
    "data = download_data(tickers, start_date, end_date, columns)\n",
    "print(data)\n",
    "\n",
    "\n",
    "def one_lvl_colnames(df,cols,tickers):\n",
    "    \"\"\"This function changes a multi-level column indexation into a one level\n",
    "    column indexation\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "    df (pandas Dataframe): dataframe with the columns whose indexation will be \n",
    "        flattened.\n",
    "    tickers (list|string): list/string with the tickers (s) in the data frame df.\n",
    "    cols (list|string): list/string with the name of the columns (e.g. 'Adj Close',\n",
    "        'High', 'Close', etc.) that are in the dataframe df.\n",
    "    \n",
    "    Ouputs:\n",
    "    -------\n",
    "    df (pandas Dataframe): dataframe with the same information as df, but \n",
    "        with one level of indexation.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    print(\"the dataframe before the columns were renamed\")\n",
    "#     print(df.columns)\n",
    "    df_not_renamed=df.copy()\n",
    "#     df_not_renamed.drop(\"Open\",inplace=True)\n",
    "    print(df_not_renamed.columns)\n",
    "    # Define important variables:\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    if isinstance(cols, str):\n",
    "        \n",
    "        cols = [cols]\n",
    "        print(cols)\n",
    "\n",
    "    # For multi-level column indexing:\n",
    "    if isinstance(df.columns.values[0], tuple):\n",
    "\n",
    "        # Define important varibles\n",
    "        columns = df.columns.values\n",
    "        new_cols = []\n",
    "\n",
    "        # Itarate through the multi-level column names and flatten them:\n",
    "        for col in columns:\n",
    "            temp = []\n",
    "            for name in col:\n",
    "                if name != '':\n",
    "                    temp.append(name)\n",
    "            new_temp = '_'.join(temp)\n",
    "            new_cols.append(new_temp)\n",
    "        \n",
    "        # Change the column names:\n",
    "        df.columns = new_cols\n",
    "        print(df.columns)\n",
    "    \n",
    "    # For uni-level colum indexing:\n",
    "    elif isinstance(df.columns.values[0], str):\n",
    "        \n",
    "        # Define new names:\n",
    "        col_names = [column+'_'+ticker for column in cols\\\n",
    "                     for ticker in tickers]\n",
    "        df.columns = col_names\n",
    "    \n",
    "    print(\"the dataframe after the columns have been renamed\") \n",
    "#     print(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "df2=pd.DataFrame(one_lvl_colnames(data,cols=columns,tickers=tickers))\n",
    "df2_columns=list(df2.columns)\n",
    "df2.columns = [col.replace('Adj Close', 'Close') for col in df2_columns]\n",
    "df2.fillna(method='ffill',inplace=True)\n",
    "df2.fillna(method='bfill',inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abafca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_statistics(df,cols='Adj Close',tickers=None,functions=None,\n",
    "                      window=20,bollinger=False,roll_linewidth=1.5,**kwargs):\n",
    "        '''This method extracts the rolling statistics from a time series, and\n",
    "        can plot the rolling window with the data, adding the Bollinger bands.\n",
    "        \n",
    "        Inputs:\n",
    "        -------\n",
    "        column (string, default=None): the column from which you want compute \n",
    "            the rolling function.\n",
    "        tickers (str|list, default=None): the ticker(s) from which you want to know the \n",
    "            information.\n",
    "        functions (function|string|list): function(s) that will be rolled through the \n",
    "            time series.\n",
    "        window (int): the window of the rolling data\n",
    "            \n",
    "        OUTPUTS:\n",
    "            rolled (pandas series): a series with the rolling statistics specified\n",
    "\n",
    "        '''\n",
    "        # Define important varibles:\n",
    "#         df = self.df\n",
    "#         if isinstance(tickers,type(None)):\n",
    "#             tickers = self.get_tickers()\n",
    "        col_names = cols\n",
    "        if isinstance(functions,type(None)):\n",
    "            functions = [momentum, simple_moving_average, bollinger_bands]\n",
    "        elif not isinstance(functions,list):\n",
    "            functions = [functions]\n",
    "\n",
    "        # Define the actual dataframe analized\n",
    "        df = df[col_names]\n",
    "\n",
    "        # Compute the rolling statistics:\n",
    "        rolling_stats = df.rolling(window).agg(functions)\n",
    "        \n",
    "        return rolling_stats\n",
    "        \n",
    "#         print(rolling_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2180b7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "BBWI\n",
      "                close    volume       open       high        low\n",
      "Date                                                            \n",
      "2007-01-03  10.077240   9288633  24.252222  24.276476  23.540825\n",
      "2007-01-04   9.317529  17476831  22.546482  22.756668  21.891672\n",
      "2007-01-05   9.310719   9970096  21.980598  22.433306  21.147940\n",
      "2007-01-08   9.130162   9207238  22.029102  22.465643  21.471302\n",
      "2007-01-09   9.266431  10808659  21.843168  22.465643  21.827002\n",
      "...               ...       ...        ...        ...        ...\n",
      "2022-12-23  41.287590   2461500  40.330002  41.950001  40.150002\n",
      "2022-12-27  41.297436   3022500  41.939999  42.889999  41.810001\n",
      "2022-12-28  40.116104   2138000  41.779999  42.169998  40.630001\n",
      "2022-12-29  41.002102   1610500  41.349998  42.000000  41.180000\n",
      "2022-12-30  41.484478   2237000  41.099998  42.209999  40.880001\n",
      "\n",
      "[4028 rows x 5 columns]\n",
      "                close    volume       open       high        low        cci  \\\n",
      "Date                                                                          \n",
      "2007-01-03  10.077240   9288633  24.252222  24.276476  23.540825        NaN   \n",
      "2007-01-04   9.317529  17476831  22.546482  22.756668  21.891672 -66.666667   \n",
      "2007-01-05   9.310719   9970096  21.980598  22.433306  21.147940 -68.036196   \n",
      "2007-01-08   9.130162   9207238  22.029102  22.465643  21.471302 -53.794416   \n",
      "2007-01-09   9.266431  10808659  21.843168  22.465643  21.827002 -33.004958   \n",
      "...               ...       ...        ...        ...        ...        ...   \n",
      "2022-12-23  41.287590   2461500  40.330002  41.950001  40.150002 -26.952787   \n",
      "2022-12-27  41.297436   3022500  41.939999  42.889999  41.810001  46.300371   \n",
      "2022-12-28  40.116104   2138000  41.779999  42.169998  40.630001 -29.822213   \n",
      "2022-12-29  41.002102   1610500  41.349998  42.000000  41.180000  15.208379   \n",
      "2022-12-30  41.484478   2237000  41.099998  42.209999  40.880001  37.972594   \n",
      "\n",
      "              stochrsi       mfi        bop  supertrend_ub  supertrend_lb  \\\n",
      "Date                                                                        \n",
      "2007-01-03         NaN  0.500000 -19.268623      66.506358     -18.689057   \n",
      "2007-01-04         NaN  0.500000 -15.293659      62.557732     -17.909392   \n",
      "2007-01-05         NaN  0.500000  -9.857021      61.706632     -17.909392   \n",
      "2007-01-08         NaN  0.500000 -12.972352      61.706632     -17.821896   \n",
      "2007-01-09  100.000000  0.500000 -19.692958      61.706632     -17.693891   \n",
      "...                ...       ...        ...            ...            ...   \n",
      "2022-12-23   50.075568  0.271783   0.531994      46.013340      36.396208   \n",
      "2022-12-27   50.367960  0.338524  -0.594967      46.013340      36.489214   \n",
      "2022-12-28    6.012631  0.345384  -1.080453      46.013340      36.489214   \n",
      "2022-12-29   43.168234  0.393974  -0.424264      46.013340      36.489214   \n",
      "2022-12-30   62.418129  0.358997   0.289083      46.013340      36.489214   \n",
      "\n",
      "            supertrend    eribull    eribear       cti        qqe  qqel  \\\n",
      "Date                                                                      \n",
      "2007-01-03   66.506358  14.199236  13.463585  0.000000   0.000000   0.0   \n",
      "2007-01-04   62.557732  12.787958  11.922962  0.000000   0.000000   0.0   \n",
      "2007-01-05   61.706632  12.558595  11.273229  0.000000   0.000000   0.0   \n",
      "2007-01-08   61.706632  12.697296  11.702955  0.000000   0.000000   0.0   \n",
      "2007-01-09   61.706632  12.768998  12.130357  0.000000   0.000000   0.0   \n",
      "...                ...        ...        ...       ...        ...   ...   \n",
      "2022-12-23   36.396208   1.387833  -0.412166 -0.626138  58.759497   0.0   \n",
      "2022-12-27   36.489214   2.222794   1.142796 -0.425821  58.759497   0.0   \n",
      "2022-12-28   36.489214   1.581521   0.041524 -0.382262  58.759497   0.0   \n",
      "2022-12-29   36.489214   1.352434   0.532434 -0.170031  58.759497   0.0   \n",
      "2022-12-30   36.489214   1.442874   0.112876  0.214673  58.759497   0.0   \n",
      "\n",
      "                 qqes       ker  \n",
      "Date                             \n",
      "2007-01-03   0.000000  0.000000  \n",
      "2007-01-04   0.000000  1.000000  \n",
      "2007-01-05   0.000000  1.000000  \n",
      "2007-01-08   0.000000  1.000000  \n",
      "2007-01-09   0.000000  0.748430  \n",
      "...               ...       ...  \n",
      "2022-12-23  58.759497  0.061977  \n",
      "2022-12-27  58.759497  0.034364  \n",
      "2022-12-28  58.759497  0.243722  \n",
      "2022-12-29  58.759497  0.076102  \n",
      "2022-12-30  58.759497  0.051931  \n",
      "\n",
      "[4028 rows x 19 columns]\n",
      "*******************************\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "BIIB\n",
      "                 close   volume        open        high         low\n",
      "Date                                                               \n",
      "2007-01-03   49.330002  3833500   49.279999   50.250000   48.200001\n",
      "2007-01-04   49.750000  2884300   49.270000   50.099998   48.880001\n",
      "2007-01-05   49.759998  2230400   49.990002   50.330002   49.509998\n",
      "2007-01-08   50.020000  3160200   50.000000   50.160000   48.910000\n",
      "2007-01-09   49.500000  2816500   49.880001   50.139999   49.299999\n",
      "...                ...      ...         ...         ...         ...\n",
      "2022-12-23  279.160004   624800  280.450012  280.450012  276.070007\n",
      "2022-12-27  274.769989   638600  279.890015  279.890015  273.380005\n",
      "2022-12-28  274.040009   521000  275.640015  276.920013  272.640015\n",
      "2022-12-29  276.000000   594000  274.829987  279.140015  274.299988\n",
      "2022-12-30  276.920013   640700  274.980011  277.149994  272.200012\n",
      "\n",
      "[4028 rows x 5 columns]\n",
      "                 close   volume        open        high         low  \\\n",
      "Date                                                                  \n",
      "2007-01-03   49.330002  3833500   49.279999   50.250000   48.200001   \n",
      "2007-01-04   49.750000  2884300   49.270000   50.099998   48.880001   \n",
      "2007-01-05   49.759998  2230400   49.990002   50.330002   49.509998   \n",
      "2007-01-08   50.020000  3160200   50.000000   50.160000   48.910000   \n",
      "2007-01-09   49.500000  2816500   49.880001   50.139999   49.299999   \n",
      "...                ...      ...         ...         ...         ...   \n",
      "2022-12-23  279.160004   624800  280.450012  280.450012  276.070007   \n",
      "2022-12-27  274.769989   638600  279.890015  279.890015  273.380005   \n",
      "2022-12-28  274.040009   521000  275.640015  276.920013  272.640015   \n",
      "2022-12-29  276.000000   594000  274.829987  279.140015  274.299988   \n",
      "2022-12-30  276.920013   640700  274.980011  277.149994  272.200012   \n",
      "\n",
      "                   cci   stochrsi       mfi       bop  supertrend_ub  \\\n",
      "Date                                                                   \n",
      "2007-01-03         NaN        NaN  0.500000  0.024392      55.374998   \n",
      "2007-01-04   66.666667        NaN  0.500000  0.393443      54.348884   \n",
      "2007-01-05   97.111977        NaN  0.500000 -0.280491      53.919324   \n",
      "2007-01-08   35.474059        NaN  0.500000  0.016000      53.464903   \n",
      "2007-01-09   16.288392   0.000000  0.500000 -0.452382      53.324661   \n",
      "...                ...        ...       ...       ...            ...   \n",
      "2022-12-23 -168.219485   0.000000  0.234940 -0.294522     299.126919   \n",
      "2022-12-27 -168.306558   0.000000  0.241585 -0.786485     297.406427   \n",
      "2022-12-28 -156.632806   0.000000  0.251803 -0.373833     294.984902   \n",
      "2022-12-29 -104.636180  19.227311  0.314250  0.241737     294.984902   \n",
      "2022-12-30  -99.314755  28.296153  0.322954  0.391921     294.172072   \n",
      "\n",
      "            supertrend_lb  supertrend   eribull    eribear       cti  \\\n",
      "Date                                                                   \n",
      "2007-01-03      43.075003   55.374998  0.919998  -1.130001  0.000000   \n",
      "2007-01-04      44.631116   54.348884  0.709997  -0.510001  0.000000   \n",
      "2007-01-05      45.920676   53.919324  0.887144   0.067140  0.000000   \n",
      "2007-01-08      45.920676   53.464903  0.634693  -0.615307  0.000000   \n",
      "2007-01-09      46.115338   53.324661  0.618308  -0.221693  0.000000   \n",
      "...                   ...         ...       ...        ...       ...   \n",
      "2022-12-23     257.393101  299.126919 -5.956845 -10.336850 -0.699009   \n",
      "2022-12-27     257.393101  297.406427 -4.854433 -11.364443 -0.764786   \n",
      "2022-12-28     257.393101  294.984902 -6.295229 -10.575227 -0.889266   \n",
      "2022-12-29     257.393101  294.984902 -3.044479  -7.884505 -0.888977   \n",
      "2022-12-30     257.393101  294.172072 -4.282431  -9.232412 -0.853851   \n",
      "\n",
      "                  qqe  qqel       qqes       ker  \n",
      "Date                                              \n",
      "2007-01-03   0.000000   0.0   0.000000  0.000000  \n",
      "2007-01-04   0.000000   0.0   0.000000  1.000000  \n",
      "2007-01-05   0.000000   0.0   0.000000  1.000000  \n",
      "2007-01-08   0.000000   0.0   0.000000  1.000000  \n",
      "2007-01-09   0.000000   0.0   0.000000  0.140494  \n",
      "...               ...   ...        ...       ...  \n",
      "2022-12-23  49.138925   0.0  49.138925  0.227555  \n",
      "2022-12-27  46.756338   0.0  46.756338  0.597883  \n",
      "2022-12-28  44.980886   0.0  44.980886  0.648077  \n",
      "2022-12-29  44.751224   0.0  44.751224  0.496009  \n",
      "2022-12-30  44.751224   0.0  44.751224  0.301572  \n",
      "\n",
      "[4028 rows x 19 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "CBRE\n",
      "                close   volume       open       high        low\n",
      "Date                                                           \n",
      "2007-01-03  33.650002  2079600  33.400002  33.830002  33.139999\n",
      "2007-01-04  33.340000  1354900  33.810001  34.000000  33.099998\n",
      "2007-01-05  33.099998  1374100  33.340000  33.599998  32.799999\n",
      "2007-01-08  33.220001   960400  33.410000  33.410000  32.500000\n",
      "2007-01-09  33.970001  1457300  33.380001  34.200001  33.060001\n",
      "...               ...      ...        ...        ...        ...\n",
      "2022-12-23  76.669998   675000  75.279999  76.669998  75.150002\n",
      "2022-12-27  76.489998   599500  76.820000  77.120003  76.099998\n",
      "2022-12-28  75.410004   746600  76.599998  76.910004  75.379997\n",
      "2022-12-29  77.550003   884900  75.870003  77.669998  75.769997\n",
      "2022-12-30  76.959999  1175600  76.720001  77.320000  76.089996\n",
      "\n",
      "[4028 rows x 5 columns]\n",
      "                close   volume       open       high        low         cci  \\\n",
      "Date                                                                          \n",
      "2007-01-03  33.650002  2079600  33.400002  33.830002  33.139999         NaN   \n",
      "2007-01-04  33.340000  1354900  33.810001  34.000000  33.099998  -66.666667   \n",
      "2007-01-05  33.099998  1374100  33.340000  33.599998  32.799999 -100.000000   \n",
      "2007-01-08  33.220001   960400  33.410000  33.410000  32.500000  -86.968148   \n",
      "2007-01-09  33.970001  1457300  33.380001  34.200001  33.060001  100.306946   \n",
      "...               ...      ...        ...        ...        ...         ...   \n",
      "2022-12-23  76.669998   675000  75.279999  76.669998  75.150002  -34.504067   \n",
      "2022-12-27  76.489998   599500  76.820000  77.120003  76.099998   -6.013576   \n",
      "2022-12-28  75.410004   746600  76.599998  76.910004  75.379997  -46.738794   \n",
      "2022-12-29  77.550003   884900  75.870003  77.669998  75.769997   22.360229   \n",
      "2022-12-30  76.959999  1175600  76.720001  77.320000  76.089996    5.983182   \n",
      "\n",
      "              stochrsi       mfi       bop  supertrend_ub  supertrend_lb  \\\n",
      "Date                                                                       \n",
      "2007-01-03         NaN  0.500000  0.362318      35.555008      31.414993   \n",
      "2007-01-04         NaN  0.500000 -0.522223      35.555008      31.414993   \n",
      "2007-01-05         NaN  0.500000 -0.300002      35.555008      31.414993   \n",
      "2007-01-08  100.000000  0.500000 -0.208790      35.445343      31.414993   \n",
      "2007-01-09  100.000000  0.500000  0.517544      35.445343      31.414993   \n",
      "...                ...       ...       ...            ...            ...   \n",
      "2022-12-23   35.829868  0.280723  0.914475      81.295059      73.217118   \n",
      "2022-12-27   32.089520  0.315817 -0.323530      81.295059      73.217118   \n",
      "2022-12-28    9.913344  0.323377 -0.777771      81.295059      73.217118   \n",
      "2022-12-29   51.982018  0.372501  0.884210      81.295059      73.217118   \n",
      "2022-12-30   39.498040  0.370532  0.195120      81.295059      73.217118   \n",
      "\n",
      "            supertrend   eribull   eribear       cti        qqe  qqel  \\\n",
      "Date                                                                    \n",
      "2007-01-03   35.555008  0.180000 -0.510002  0.000000   0.000000   0.0   \n",
      "2007-01-04   35.555008  0.394284 -0.505717  0.000000   0.000000   0.0   \n",
      "2007-01-05   35.555008  0.066528 -0.733471  0.000000   0.000000   0.0   \n",
      "2007-01-08   35.445343 -0.078689 -0.988689  0.000000   0.000000   0.0   \n",
      "2007-01-09   35.445343  0.642553 -0.497447  0.000000   0.000000   0.0   \n",
      "...                ...       ...       ...       ...        ...   ...   \n",
      "2022-12-23   73.217118  0.179983 -1.340014 -0.276182  55.194492   0.0   \n",
      "2022-12-27   73.217118  0.629990 -0.390015 -0.347800  55.194492   0.0   \n",
      "2022-12-28   73.217118  0.574278 -0.955729 -0.540510  55.194492   0.0   \n",
      "2022-12-29   73.217118  1.160804 -0.739197 -0.470721  55.194492   0.0   \n",
      "2022-12-30   73.217118  0.746405 -0.483598 -0.166159  55.194492   0.0   \n",
      "\n",
      "                 qqes       ker  \n",
      "Date                             \n",
      "2007-01-03   0.000000  0.000000  \n",
      "2007-01-04   0.000000  1.000000  \n",
      "2007-01-05   0.000000  1.000000  \n",
      "2007-01-08   0.000000  0.641786  \n",
      "2007-01-09   0.000000  0.225351  \n",
      "...               ...       ...  \n",
      "2022-12-23  55.194492  0.065406  \n",
      "2022-12-27  55.194492  0.000819  \n",
      "2022-12-28  55.194492  0.448137  \n",
      "2022-12-29  55.194492  0.160069  \n",
      "2022-12-30  55.194492  0.046875  \n",
      "\n",
      "[4028 rows x 19 columns]\n",
      "*******************************\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "DIS\n",
      "                close    volume       open       high        low\n",
      "Date                                                            \n",
      "2007-01-03  28.317095  13562595  33.748165  34.073711  33.531136\n",
      "2007-01-04  28.540646   9806285  33.738300  34.083576  33.708706\n",
      "2007-01-05  28.308819  10551445  33.807354  33.975060  33.531136\n",
      "2007-01-08  28.565489   9479676  33.728436  34.162495  33.610054\n",
      "2007-01-09  28.524096  11588444  34.034248  34.221684  33.491676\n",
      "...               ...       ...        ...        ...        ...\n",
      "2022-12-23  88.010002  11171600  86.059998  88.070000  85.769997\n",
      "2022-12-27  86.370003  11561400  87.419998  87.940002  85.959999\n",
      "2022-12-28  84.169998  12399500  86.080002  86.690002  84.070000\n",
      "2022-12-29  87.180000  13045100  85.250000  88.239998  84.970001\n",
      "2022-12-30  86.879997  23231000  85.730003  87.120003  85.230003\n",
      "\n",
      "[4028 rows x 5 columns]\n",
      "                close    volume       open       high        low         cci  \\\n",
      "Date                                                                           \n",
      "2007-01-03  28.317095  13562595  33.748165  34.073711  33.531136         NaN   \n",
      "2007-01-04  28.540646   9806285  33.738300  34.083576  33.708706   66.666667   \n",
      "2007-01-05  28.308819  10551445  33.807354  33.975060  33.531136  -67.266858   \n",
      "2007-01-08  28.565489   9479676  33.728436  34.162495  33.610054   67.396108   \n",
      "2007-01-09  28.524096  11588444  34.034248  34.221684  33.491676   34.657585   \n",
      "...               ...       ...        ...        ...        ...         ...   \n",
      "2022-12-23  88.010002  11171600  86.059998  88.070000  85.769997  -79.811941   \n",
      "2022-12-27  86.370003  11561400  87.419998  87.940002  85.959999  -78.497097   \n",
      "2022-12-28  84.169998  12399500  86.080002  86.690002  84.070000 -100.034965   \n",
      "2022-12-29  87.180000  13045100  85.250000  88.239998  84.970001  -54.054532   \n",
      "2022-12-30  86.879997  23231000  85.730003  87.120003  85.230003  -55.642434   \n",
      "\n",
      "             stochrsi       mfi        bop  supertrend_ub  supertrend_lb  \\\n",
      "Date                                                                       \n",
      "2007-01-03        NaN  0.500000 -10.009790      51.072273      16.532574   \n",
      "2007-01-04        NaN  0.500000 -13.865208      51.072273      16.610946   \n",
      "2007-01-05   0.000000  0.500000 -12.386210      50.686441      16.819754   \n",
      "2007-01-08  38.614804  0.500000  -9.345704      50.686441      16.819754   \n",
      "2007-01-09  30.560185  0.500000  -7.548080      50.686441      16.819754   \n",
      "...               ...       ...        ...            ...            ...   \n",
      "2022-12-23  44.867435  0.392203   0.847827      94.827871      77.985373   \n",
      "2022-12-27  25.496638  0.393707  -0.530300      94.827871      78.191225   \n",
      "2022-12-28   2.058954  0.391571  -0.729008      94.074579      78.191225   \n",
      "2022-12-29  58.554808  0.400212   0.590215      94.074579      78.191225   \n",
      "2022-12-30  54.916148  0.331202   0.608463      94.074579      78.191225   \n",
      "\n",
      "            supertrend   eribull   eribear       cti        qqe  qqel  \\\n",
      "Date                                                                    \n",
      "2007-01-03   51.072273  5.756617  5.214041  0.000000   0.000000   0.0   \n",
      "2007-01-04   51.072273  5.734546  5.359675  0.000000   0.000000   0.0   \n",
      "2007-01-05   50.686441  5.631773  5.187849  0.000000   0.000000   0.0   \n",
      "2007-01-08   50.686441  5.787465  5.235025  0.000000   0.000000   0.0   \n",
      "2007-01-09   50.686441  5.825359  5.095352  0.000000   0.000000   0.0   \n",
      "...                ...       ...       ...       ...        ...   ...   \n",
      "2022-12-23   94.827871 -1.980303 -4.280306 -0.841567  42.758088   0.0   \n",
      "2022-12-27   94.827871 -1.584543 -3.564547 -0.872248  42.758088   0.0   \n",
      "2022-12-28   94.074579 -2.069608 -4.689611 -0.891082  41.656477   0.0   \n",
      "2022-12-29   94.074579 -0.293954 -3.563951 -0.806779  41.656477   0.0   \n",
      "2022-12-30   94.074579 -1.177670 -3.067669 -0.697686  41.656477   0.0   \n",
      "\n",
      "                 qqes       ker  \n",
      "Date                             \n",
      "2007-01-03   0.000000  0.000000  \n",
      "2007-01-04   0.000000  1.000000  \n",
      "2007-01-05   0.000000  0.018174  \n",
      "2007-01-08   0.000000  0.348845  \n",
      "2007-01-09   0.000000  0.274741  \n",
      "...               ...       ...  \n",
      "2022-12-23  42.758088  0.407745  \n",
      "2022-12-27  42.758088  0.612713  \n",
      "2022-12-28  41.656477  0.671128  \n",
      "2022-12-29  41.656477  0.384022  \n",
      "2022-12-30  41.656477  0.244084  \n",
      "\n",
      "[4028 rows x 19 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "ETR\n",
      "                 close   volume        open        high         low\n",
      "Date                                                               \n",
      "2007-01-03   46.684532  1319900   92.320000   93.419998   92.089996\n",
      "2007-01-04   47.236824  2610100   92.989998   94.160004   92.599998\n",
      "2007-01-05   46.071968  2269500   93.599998   93.690002   91.279999\n",
      "2007-01-08   45.725513  1686800   91.559998   92.459999   90.870003\n",
      "2007-01-09   45.695408  1029700   91.169998   91.620003   90.540001\n",
      "...                ...      ...         ...         ...         ...\n",
      "2022-12-23  109.924477  1166400  112.550003  113.629997  112.339996\n",
      "2022-12-27  111.164909   968500  113.639999  115.059998  113.190002\n",
      "2022-12-28  109.478691  1011700  115.160004  115.199997  112.930000\n",
      "2022-12-29  110.564072   834100  113.599998  115.059998  112.500000\n",
      "2022-12-30  109.023216   906400  114.139999  114.290001  111.489998\n",
      "\n",
      "[4028 rows x 5 columns]\n",
      "                 close   volume        open        high         low  \\\n",
      "Date                                                                  \n",
      "2007-01-03   46.684532  1319900   92.320000   93.419998   92.089996   \n",
      "2007-01-04   47.236824  2610100   92.989998   94.160004   92.599998   \n",
      "2007-01-05   46.071968  2269500   93.599998   93.690002   91.279999   \n",
      "2007-01-08   45.725513  1686800   91.559998   92.459999   90.870003   \n",
      "2007-01-09   45.695408  1029700   91.169998   91.620003   90.540001   \n",
      "...                ...      ...         ...         ...         ...   \n",
      "2022-12-23  109.924477  1166400  112.550003  113.629997  112.339996   \n",
      "2022-12-27  111.164909   968500  113.639999  115.059998  113.190002   \n",
      "2022-12-28  109.478691  1011700  115.160004  115.199997  112.930000   \n",
      "2022-12-29  110.564072   834100  113.599998  115.059998  112.500000   \n",
      "2022-12-30  109.023216   906400  114.139999  114.290001  111.489998   \n",
      "\n",
      "                   cci   stochrsi       mfi        bop  supertrend_ub  \\\n",
      "Date                                                                    \n",
      "2007-01-03         NaN        NaN  0.500000 -34.312334     232.961395   \n",
      "2007-01-04   66.666667        NaN  0.500000 -29.328860     232.961395   \n",
      "2007-01-05  -86.341796   0.000000  0.500000 -19.721144     232.961395   \n",
      "2007-01-08 -110.130116   0.000000  0.500000 -28.826786     231.895211   \n",
      "2007-01-09 -104.402100   0.000000  0.500000 -42.106031     230.722720   \n",
      "...                ...        ...       ...        ...            ...   \n",
      "2022-12-23  -84.585253  11.750740  0.506408  -2.035290     125.766472   \n",
      "2022-12-27  -38.738475  30.868226  0.509237  -1.323581     125.766472   \n",
      "2022-12-28  -51.656698   4.944260  0.503691  -2.502785     125.766472   \n",
      "2022-12-29  -40.543045  21.524299  0.500551  -1.185910     125.766472   \n",
      "2022-12-30  -71.521677   0.000000  0.456976  -1.827421     125.766472   \n",
      "\n",
      "            supertrend_lb  supertrend    eribull    eribear       cti  \\\n",
      "Date                                                                    \n",
      "2007-01-03     -47.451401  232.961395  46.735466  45.405464  0.000000   \n",
      "2007-01-04     -47.451401  232.961395  47.396573  45.836567  0.000000   \n",
      "2007-01-05     -47.451401  232.961395  47.025352  44.615348  0.000000   \n",
      "2007-01-08     -47.451401  231.895211  45.929511  44.339515  0.000000   \n",
      "2007-01-09     -47.451401  230.722720  45.208812  44.128810  0.000000   \n",
      "...                   ...         ...        ...        ...       ...   \n",
      "2022-12-23     104.140373  104.140373   2.625544   1.335543 -0.832168   \n",
      "2022-12-27     104.140373  104.140373   4.032622   2.162627 -0.791100   \n",
      "2022-12-28     104.140373  104.140373   4.393862   2.123865 -0.811727   \n",
      "2022-12-29     104.140373  104.140373   4.288443   1.728445 -0.704930   \n",
      "2022-12-30     104.140373  104.140373   3.768209   0.968206 -0.644103   \n",
      "\n",
      "                  qqe  qqel       qqes       ker  \n",
      "Date                                              \n",
      "2007-01-03   0.000000   0.0   0.000000  0.000000  \n",
      "2007-01-04   0.000000   0.0   0.000000  1.000000  \n",
      "2007-01-05   0.000000   0.0   0.000000  0.356733  \n",
      "2007-01-08   0.000000   0.0   0.000000  0.464730  \n",
      "2007-01-09   0.000000   0.0   0.000000  0.472427  \n",
      "...               ...   ...        ...       ...  \n",
      "2022-12-23  55.172406   0.0  55.172406  0.319702  \n",
      "2022-12-27  55.172406   0.0  55.172406  0.351094  \n",
      "2022-12-28  55.172406   0.0  55.172406  0.440984  \n",
      "2022-12-29  55.172406   0.0  55.172406  0.328799  \n",
      "2022-12-30  54.331727   0.0  54.331727  0.325741  \n",
      "\n",
      "[4028 rows x 19 columns]\n",
      "*******************************\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "GILD\n",
      "                close    volume       open       high        low\n",
      "Date                                                            \n",
      "2007-01-03  11.958691  33461200  16.320000  16.535000  15.480000\n",
      "2007-01-04  12.155637  18666400  15.780000  16.157499  15.617500\n",
      "2007-01-05  12.159423  14022000  16.055000  16.205000  15.962500\n",
      "2007-01-08  12.163210  12984000  15.995000  16.084999  15.877500\n",
      "2007-01-09  12.310920  20593600  16.237499  16.377501  16.129999\n",
      "...               ...       ...        ...        ...        ...\n",
      "2022-12-23  83.147980   3955400  85.220001  85.250000  84.279999\n",
      "2022-12-27  83.403076   3455900  85.250000  85.470001  84.690002\n",
      "2022-12-28  82.971390   3285900  85.400002  85.830002  84.449997\n",
      "2022-12-29  83.648346   3464100  84.910004  85.570000  84.610001\n",
      "2022-12-30  84.227188   3831000  85.330002  85.889999  84.779999\n",
      "\n",
      "[4028 rows x 5 columns]\n",
      "                close    volume       open       high        low         cci  \\\n",
      "Date                                                                           \n",
      "2007-01-03  11.958691  33461200  16.320000  16.535000  15.480000         NaN   \n",
      "2007-01-04  12.155637  18666400  15.780000  16.157499  15.617500  -66.666667   \n",
      "2007-01-05  12.159423  14022000  16.055000  16.205000  15.962500  100.000000   \n",
      "2007-01-08  12.163210  12984000  15.995000  16.084999  15.877500   17.736722   \n",
      "2007-01-09  12.310920  20593600  16.237499  16.377501  16.129999  143.994805   \n",
      "...               ...       ...        ...        ...        ...         ...   \n",
      "2022-12-23  83.147980   3955400  85.220001  85.250000  84.279999 -103.916734   \n",
      "2022-12-27  83.403076   3455900  85.250000  85.470001  84.690002  -76.826054   \n",
      "2022-12-28  82.971390   3285900  85.400002  85.830002  84.449997  -70.634146   \n",
      "2022-12-29  83.648346   3464100  84.910004  85.570000  84.610001  -53.409599   \n",
      "2022-12-30  84.227188   3831000  85.330002  85.889999  84.779999  -28.143084   \n",
      "\n",
      "             stochrsi       mfi        bop  supertrend_ub  supertrend_lb  \\\n",
      "Date                                                                       \n",
      "2007-01-03        NaN  0.500000  -4.133941      29.736427       2.278572   \n",
      "2007-01-04        NaN  0.500000  -6.711796      29.029204       2.745795   \n",
      "2007-01-05        NaN  0.500000 -16.064217      28.869424       3.298076   \n",
      "2007-01-08        NaN  0.500000 -18.466502      28.485995       3.476503   \n",
      "2007-01-09        NaN  0.500000 -15.864880      28.485995       3.717140   \n",
      "...               ...       ...        ...            ...            ...   \n",
      "2022-12-23   0.000000  0.166563  -2.136102      91.021394      78.875681   \n",
      "2022-12-27   4.775384  0.199841  -2.367855      91.021394      78.875681   \n",
      "2022-12-28   0.000000  0.209959  -1.759857      91.021394      78.875681   \n",
      "2022-12-29  16.471264  0.187511  -1.314228      91.021394      78.875681   \n",
      "2022-12-30  29.668153  0.231504  -0.993525      91.021394      78.875681   \n",
      "\n",
      "            supertrend   eribull   eribear       cti        qqe  qqel  \\\n",
      "Date                                                                    \n",
      "2007-01-03   29.736427  4.576309  3.521309  0.000000   0.000000   0.0   \n",
      "2007-01-04   29.029204  4.170674  3.630674  0.000000   0.000000   0.0   \n",
      "2007-01-05   28.869424  4.193517  3.951017  0.000000   0.000000   0.0   \n",
      "2007-01-08   28.485995  4.051841  3.844342  0.000000   0.000000   0.0   \n",
      "2007-01-09   28.485995  4.304662  4.057161  0.000000   0.000000   0.0   \n",
      "...                ...       ...       ...       ...        ...   ...   \n",
      "2022-12-23   78.875681  0.895287 -0.074714 -0.903681  59.284353   0.0   \n",
      "2022-12-27   78.875681  1.251236  0.471238 -0.882358  58.589168   0.0   \n",
      "2022-12-28   78.875681  1.789433  0.409428 -0.917740  57.352054   0.0   \n",
      "2022-12-29   78.875681  1.585463  0.625464 -0.861716  57.352054   0.0   \n",
      "2022-12-30   78.875681  1.870798  0.760798 -0.702355  57.352054   0.0   \n",
      "\n",
      "                 qqes       ker  \n",
      "Date                             \n",
      "2007-01-03   0.000000  0.000000  \n",
      "2007-01-04   0.000000  1.000000  \n",
      "2007-01-05   0.000000  1.000000  \n",
      "2007-01-08   0.000000  1.000000  \n",
      "2007-01-09   0.000000  1.000000  \n",
      "...               ...       ...  \n",
      "2022-12-23  59.284353  0.403718  \n",
      "2022-12-27  58.589168  0.476621  \n",
      "2022-12-28  57.352054  0.564646  \n",
      "2022-12-29  57.352054  0.489095  \n",
      "2022-12-30  57.352054  0.140656  \n",
      "\n",
      "[4028 rows x 19 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "NI\n",
      "                close   volume       open       high        low\n",
      "Date                                                           \n",
      "2007-01-03   4.979854  3227315   9.469548   9.622790   9.469548\n",
      "2007-01-04   4.961387  2680140   9.536346   9.591356   9.469548\n",
      "2007-01-05   4.836224  4132062   9.481336   9.481336   9.229862\n",
      "2007-01-08   4.828016  3449748   9.261297   9.343811   9.182711\n",
      "2007-01-09   4.842379  4279927   9.253438   9.300589   9.210216\n",
      "...               ...      ...        ...        ...        ...\n",
      "2022-12-23  26.970551  1588400  27.330000  27.709999  27.330000\n",
      "2022-12-27  27.058151  1994900  27.740000  27.879999  27.549999\n",
      "2022-12-28  26.814819  1944100  27.780001  28.020000  27.520000\n",
      "2022-12-29  27.097084  1431600  27.639999  27.920000  27.639999\n",
      "2022-12-30  26.688292  2526900  27.820000  27.870001  27.230000\n",
      "\n",
      "[4028 rows x 5 columns]\n",
      "                close   volume       open       high        low         cci  \\\n",
      "Date                                                                          \n",
      "2007-01-03   4.979854  3227315   9.469548   9.622790   9.469548         NaN   \n",
      "2007-01-04   4.961387  2680140   9.536346   9.591356   9.469548  -66.666667   \n",
      "2007-01-05   4.836224  4132062   9.481336   9.481336   9.229862 -100.000000   \n",
      "2007-01-08   4.828016  3449748   9.261297   9.343811   9.182711  -88.232566   \n",
      "2007-01-09   4.842379  4279927   9.253438   9.300589   9.210216  -69.954996   \n",
      "...               ...      ...        ...        ...        ...         ...   \n",
      "2022-12-23  26.970551  1588400  27.330000  27.709999  27.330000   12.777623   \n",
      "2022-12-27  27.058151  1994900  27.740000  27.879999  27.549999   52.455274   \n",
      "2022-12-28  26.814819  1944100  27.780001  28.020000  27.520000   40.843992   \n",
      "2022-12-29  27.097084  1431600  27.639999  27.920000  27.639999   63.295786   \n",
      "2022-12-30  26.688292  2526900  27.820000  27.870001  27.230000   -8.882861   \n",
      "\n",
      "              stochrsi       mfi        bop  supertrend_ub  supertrend_lb  \\\n",
      "Date                                                                        \n",
      "2007-01-03         NaN  0.500000 -29.298044      23.474978      -4.382639   \n",
      "2007-01-04         NaN  0.500000 -37.558759      23.410364      -4.349459   \n",
      "2007-01-05         NaN  0.500000 -18.471580      23.120825      -4.349459   \n",
      "2007-01-08         NaN  0.500000 -27.518748      22.960975      -4.349459   \n",
      "2007-01-09  100.000000  0.500000 -48.809456      22.888526      -4.349459   \n",
      "...                ...       ...        ...            ...            ...   \n",
      "2022-12-23   52.995216  0.447503  -0.945922      28.274639      24.894747   \n",
      "2022-12-27   63.484781  0.434036  -2.066208      28.274639      24.894747   \n",
      "2022-12-28   35.074915  0.467603  -1.930363      28.274639      24.894747   \n",
      "2022-12-29   60.618175  0.430891  -1.938979      28.274639      24.894747   \n",
      "2022-12-30   15.455362  0.447247  -1.768290      28.274639      24.894747   \n",
      "\n",
      "            supertrend   eribull   eribear       cti        qqe  qqel  \\\n",
      "Date                                                                    \n",
      "2007-01-03   23.474978  4.642936  4.489694  0.000000   0.000000   0.0   \n",
      "2007-01-04   23.410364  4.614140  4.492332  0.000000   0.000000   0.0   \n",
      "2007-01-05   23.120825  4.524261  4.272788  0.000000   0.000000   0.0   \n",
      "2007-01-08   22.960975  4.405174  4.244073  0.000000   0.000000   0.0   \n",
      "2007-01-09   22.888526  4.375702  4.285329  0.000000   0.000000   0.0   \n",
      "...                ...       ...       ...       ...        ...   ...   \n",
      "2022-12-23   28.274639  0.997882  0.617883 -0.412513  57.736577   0.0   \n",
      "2022-12-27   28.274639  1.118449  0.788449 -0.186689  57.736577   0.0   \n",
      "2022-12-28   28.274639  1.250840  0.750840 -0.255726  57.736577   0.0   \n",
      "2022-12-29   28.274639  1.103994  0.823993  0.135932  57.736577   0.0   \n",
      "2022-12-30   28.274639  1.072239  0.432238  0.328217  57.736577   0.0   \n",
      "\n",
      "                 qqes       ker  \n",
      "Date                             \n",
      "2007-01-03   0.000000  0.000000  \n",
      "2007-01-04   0.000000  1.000000  \n",
      "2007-01-05   0.000000  1.000000  \n",
      "2007-01-08   0.000000  1.000000  \n",
      "2007-01-09   0.000000  0.827163  \n",
      "...               ...       ...  \n",
      "2022-12-23  57.736577  0.121212  \n",
      "2022-12-27  57.736577  0.137255  \n",
      "2022-12-28  57.736577  0.177572  \n",
      "2022-12-29  57.736577  0.008621  \n",
      "2022-12-30  57.736577  0.008475  \n",
      "\n",
      "[4028 rows x 19 columns]\n",
      "*******************************\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "NVDA\n",
      "                 close     volume        open        high         low\n",
      "Date                                                                 \n",
      "2007-01-03    5.516786  115482000    6.178333    6.253333    5.798333\n",
      "2007-01-04    5.490792   79729800    5.991667    6.013333    5.838333\n",
      "2007-01-05    5.146760  124334400    5.843333    5.866667    5.570000\n",
      "2007-01-08    5.184986   65727000    5.630000    5.760000    5.533333\n",
      "2007-01-09    5.084071   76416600    5.660000    5.698333    5.535000\n",
      "...                ...        ...         ...         ...         ...\n",
      "2022-12-23  152.005920   34932600  151.960007  153.389999  148.830002\n",
      "2022-12-27  141.159790   46490200  150.740005  151.000000  140.559998\n",
      "2022-12-28  140.310074   35106600  139.270004  142.619995  138.839996\n",
      "2022-12-29  145.978073   35492300  144.020004  146.830002  142.270004\n",
      "2022-12-30  146.088028   31049000  143.339996  146.289993  142.330002\n",
      "\n",
      "[4028 rows x 5 columns]\n",
      "                 close     volume        open        high         low  \\\n",
      "Date                                                                    \n",
      "2007-01-03    5.516786  115482000    6.178333    6.253333    5.798333   \n",
      "2007-01-04    5.490792   79729800    5.991667    6.013333    5.838333   \n",
      "2007-01-05    5.146760  124334400    5.843333    5.866667    5.570000   \n",
      "2007-01-08    5.184986   65727000    5.630000    5.760000    5.533333   \n",
      "2007-01-09    5.084071   76416600    5.660000    5.698333    5.535000   \n",
      "...                ...        ...         ...         ...         ...   \n",
      "2022-12-23  152.005920   34932600  151.960007  153.389999  148.830002   \n",
      "2022-12-27  141.159790   46490200  150.740005  151.000000  140.559998   \n",
      "2022-12-28  140.310074   35106600  139.270004  142.619995  138.839996   \n",
      "2022-12-29  145.978073   35492300  144.020004  146.830002  142.270004   \n",
      "2022-12-30  146.088028   31049000  143.339996  146.289993  142.330002   \n",
      "\n",
      "                   cci    stochrsi       mfi       bop  supertrend_ub  \\\n",
      "Date                                                                    \n",
      "2007-01-03         NaN         NaN  0.500000 -1.453949       8.235474   \n",
      "2007-01-04  -66.666667         NaN  0.500000 -2.862148       7.762140   \n",
      "2007-01-05 -100.000000         NaN  0.500000 -2.347997       7.300707   \n",
      "2007-01-08  -74.245496  100.000000  0.500000 -1.963293       7.300695   \n",
      "2007-01-09  -75.405822   77.765336  0.500000 -3.526103       7.244400   \n",
      "...                ...         ...       ...       ...            ...   \n",
      "2022-12-23 -145.777971    0.000000  0.399487  0.010069     173.975079   \n",
      "2022-12-27 -173.658566    0.000000  0.395637 -0.917645     169.464555   \n",
      "2022-12-28 -162.467857    0.000000  0.399486  0.275151     163.532798   \n",
      "2022-12-29 -105.498270   17.097380  0.378743  0.429401     163.532798   \n",
      "2022-12-30  -88.937603   17.423973  0.310450  0.693949     163.532798   \n",
      "\n",
      "            supertrend_lb  supertrend    eribull    eribear       cti  \\\n",
      "Date                                                                    \n",
      "2007-01-03       3.816192    8.235474   0.736547   0.281547  0.000000   \n",
      "2007-01-04       4.089526    7.762140   0.500260   0.325261  0.000000   \n",
      "2007-01-05       4.135960    7.300707   0.405924   0.109258  0.000000   \n",
      "2007-01-08       4.135960    7.300695   0.338652   0.111984  0.000000   \n",
      "2007-01-09       4.135960    7.244400   0.325167   0.161834  0.000000   \n",
      "...                   ...         ...        ...        ...       ...   \n",
      "2022-12-23     128.244922  173.975079  -9.399082 -13.959080 -0.831194   \n",
      "2022-12-27     128.244922  169.464555  -8.699183 -19.139185 -0.892057   \n",
      "2022-12-28     128.244922  163.532798 -14.309315 -18.089314 -0.956924   \n",
      "2022-12-29     128.244922  163.532798  -8.534846 -13.094843 -0.957282   \n",
      "2022-12-30     128.244922  163.532798  -7.749594 -11.709586 -0.929410   \n",
      "\n",
      "                  qqe  qqel       qqes       ker  \n",
      "Date                                              \n",
      "2007-01-03   0.000000   0.0   0.000000  0.000000  \n",
      "2007-01-04   0.000000   0.0   0.000000  1.000000  \n",
      "2007-01-05   0.000000   0.0   0.000000  1.000000  \n",
      "2007-01-08   0.000000   0.0   0.000000  0.812737  \n",
      "2007-01-09   0.000000   0.0   0.000000  0.849852  \n",
      "...               ...   ...        ...       ...  \n",
      "2022-12-23  53.941024   0.0  53.941024  0.376389  \n",
      "2022-12-27  50.243174   0.0  50.243174  0.641730  \n",
      "2022-12-28  47.667327   0.0  47.667327  0.829088  \n",
      "2022-12-29  47.667327   0.0  47.667327  0.609688  \n",
      "2022-12-30  47.667327   0.0  47.667327  0.540453  \n",
      "\n",
      "[4028 rows x 19 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "PEP\n",
      "                 close   volume        open        high         low\n",
      "Date                                                               \n",
      "2007-01-03   38.873482  6161600   62.700001   63.349998   62.450001\n",
      "2007-01-04   39.139996  5414300   62.700001   63.250000   62.500000\n",
      "2007-01-05   39.016037  4542400   62.700001   63.220001   62.700001\n",
      "2007-01-08   39.102821  6122600   63.000000   63.270000   62.860001\n",
      "2007-01-09   39.263969  4916500   63.049999   63.470001   63.009998\n",
      "...                ...      ...         ...         ...         ...\n",
      "2022-12-23  178.524826  2197800  180.910004  182.550003  180.449997\n",
      "2022-12-27  179.318237  3045000  183.279999  183.610001  182.270004\n",
      "2022-12-28  178.025269  2694300  184.100006  184.539993  181.639999\n",
      "2022-12-29  178.250565  2549200  181.919998  182.860001  181.889999\n",
      "2022-12-30  176.957626  3136200  181.380005  181.960007  179.289993\n",
      "\n",
      "[4028 rows x 5 columns]\n",
      "                 close   volume        open        high         low  \\\n",
      "Date                                                                  \n",
      "2007-01-03   38.873482  6161600   62.700001   63.349998   62.450001   \n",
      "2007-01-04   39.139996  5414300   62.700001   63.250000   62.500000   \n",
      "2007-01-05   39.016037  4542400   62.700001   63.220001   62.700001   \n",
      "2007-01-08   39.102821  6122600   63.000000   63.270000   62.860001   \n",
      "2007-01-09   39.263969  4916500   63.049999   63.470001   63.009998   \n",
      "...                ...      ...         ...         ...         ...   \n",
      "2022-12-23  178.524826  2197800  180.910004  182.550003  180.449997   \n",
      "2022-12-27  179.318237  3045000  183.279999  183.610001  182.270004   \n",
      "2022-12-28  178.025269  2694300  184.100006  184.539993  181.639999   \n",
      "2022-12-29  178.250565  2549200  181.919998  182.860001  181.889999   \n",
      "2022-12-30  176.957626  3136200  181.380005  181.960007  179.289993   \n",
      "\n",
      "                   cci   stochrsi       mfi        bop  supertrend_ub  \\\n",
      "Date                                                                    \n",
      "2007-01-03         NaN        NaN  0.500000 -26.473977     136.329550   \n",
      "2007-01-04   66.666667        NaN  0.500000 -31.413340     136.148997   \n",
      "2007-01-05   64.416416   0.000000  0.500000 -45.546044     135.863504   \n",
      "2007-01-08  132.031910  20.103448  0.500000 -58.285823     135.863504   \n",
      "2007-01-09  137.507625  43.012927  0.500000 -51.708435     135.863504   \n",
      "...                ...        ...       ...        ...            ...   \n",
      "2022-12-23  -27.462816  51.423867  0.387887  -1.135796     196.524025   \n",
      "2022-12-27   42.298884  72.204486  0.446895  -2.956546     196.524025   \n",
      "2022-12-28   19.545390  32.881672  0.456875  -2.094741     196.524025   \n",
      "2022-12-29   -1.132403  39.471353  0.408744  -3.782916     196.524025   \n",
      "2022-12-30  -85.124203   0.961706  0.362264  -1.656313     196.340882   \n",
      "\n",
      "            supertrend_lb  supertrend    eribull    eribear       cti  \\\n",
      "Date                                                                    \n",
      "2007-01-03     -10.529551  136.329550  24.476517  23.576519  0.000000   \n",
      "2007-01-04     -10.398997  136.148997  24.338445  23.588445  0.000000   \n",
      "2007-01-05      -9.943502  135.863504  24.293520  23.773520  0.000000   \n",
      "2007-01-08      -9.799072  135.863504  24.318328  23.908328  0.000000   \n",
      "2007-01-09      -9.678853  135.863504  24.473715  24.013712  0.000000   \n",
      "...                   ...         ...        ...        ...       ...   \n",
      "2022-12-23     167.693077  167.693077   4.268297   2.168291 -0.589186   \n",
      "2022-12-27     167.693077  167.693077   5.180219   3.840222 -0.339993   \n",
      "2022-12-28     167.693077  167.693077   6.167999   3.268005 -0.280707   \n",
      "2022-12-29     167.693077  167.693077   4.505353   3.535352 -0.059573   \n",
      "2022-12-30     167.693077  167.693077   3.804934   1.134921  0.075185   \n",
      "\n",
      "                  qqe  qqel       qqes       ker  \n",
      "Date                                              \n",
      "2007-01-03   0.000000   0.0   0.000000  0.000000  \n",
      "2007-01-04   0.000000   0.0   0.000000  1.000000  \n",
      "2007-01-05   0.000000   0.0   0.000000  0.365084  \n",
      "2007-01-08   0.000000   0.0   0.000000  0.480537  \n",
      "2007-01-09   0.000000   0.0   0.000000  0.611662  \n",
      "...               ...   ...        ...       ...  \n",
      "2022-12-23  56.366515   0.0  56.366515  0.087137  \n",
      "2022-12-27  56.366515   0.0  56.366515  0.093945  \n",
      "2022-12-28  56.366515   0.0  56.366515  0.196297  \n",
      "2022-12-29  56.366515   0.0  56.366515  0.131179  \n",
      "2022-12-30  55.527847   0.0  55.527847  0.046966  \n",
      "\n",
      "[4028 rows x 19 columns]\n",
      "*******************************\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "SWK\n",
      "                close   volume       open       high        low\n",
      "Date                                                           \n",
      "2007-01-03  34.064182   666400  50.450001  50.799999  50.049999\n",
      "2007-01-04  34.278854   753200  50.750000  51.290001  50.259998\n",
      "2007-01-05  34.144657  1146400  51.000000  51.189999  50.590000\n",
      "2007-01-08  34.017239   750800  50.700001  50.860001  49.950001\n",
      "2007-01-09  34.634388  1000100  50.959999  51.730000  50.680000\n",
      "...               ...      ...        ...        ...        ...\n",
      "2022-12-23  71.870193   891200  73.290001  74.139999  72.599998\n",
      "2022-12-27  72.327049  1128100  73.940002  74.650002  73.250000\n",
      "2022-12-28  70.159462  1225600  74.459999  75.110001  72.160004\n",
      "2022-12-29  73.785049  1517000  72.879997  76.400002  72.769997\n",
      "2022-12-30  73.017166  1479000  75.000000  75.699997  74.330002\n",
      "\n",
      "[4028 rows x 5 columns]\n",
      "                close   volume       open       high        low         cci  \\\n",
      "Date                                                                          \n",
      "2007-01-03  34.064182   666400  50.450001  50.799999  50.049999         NaN   \n",
      "2007-01-04  34.278854   753200  50.750000  51.290001  50.259998   66.666667   \n",
      "2007-01-05  34.144657  1146400  51.000000  51.189999  50.590000   57.464541   \n",
      "2007-01-08  34.017239   750800  50.700001  50.860001  49.950001  -72.427895   \n",
      "2007-01-09  34.634388  1000100  50.959999  51.730000  50.680000  133.042567   \n",
      "...               ...      ...        ...        ...        ...         ...   \n",
      "2022-12-23  71.870193   891200  73.290001  74.139999  72.599998 -102.259927   \n",
      "2022-12-27  72.327049  1128100  73.940002  74.650002  73.250000  -74.373296   \n",
      "2022-12-28  70.159462  1225600  74.459999  75.110001  72.160004  -83.875857   \n",
      "2022-12-29  73.785049  1517000  72.879997  76.400002  72.769997  -35.701091   \n",
      "2022-12-30  73.017166  1479000  75.000000  75.699997  74.330002  -29.852652   \n",
      "\n",
      "             stochrsi       mfi        bop  supertrend_ub  supertrend_lb  \\\n",
      "Date                                                                       \n",
      "2007-01-03        NaN  0.500000 -21.847758     100.632450       0.217548   \n",
      "2007-01-04        NaN  0.500000 -15.991363     100.632450       0.217548   \n",
      "2007-01-05   0.000000  0.500000 -28.092310     100.632450       0.217548   \n",
      "2007-01-08   0.000000  0.500000 -18.332709     100.632450       0.217548   \n",
      "2007-01-09  60.324107  0.500000 -15.548212     100.632450       0.217548   \n",
      "...               ...       ...        ...            ...            ...   \n",
      "2022-12-23  10.566837  0.291036  -0.921952      83.126924      70.814805   \n",
      "2022-12-27  18.099760  0.363544  -1.152108      83.126924      70.814805   \n",
      "2022-12-28   0.000000  0.369272  -1.457811      83.126924      70.814805   \n",
      "2022-12-29  50.989841  0.376644   0.249325      83.126924      63.607290   \n",
      "2022-12-30  42.631822  0.365112  -1.447329      83.126924      64.411067   \n",
      "\n",
      "            supertrend    eribull    eribear       cti        qqe  qqel  \\\n",
      "Date                                                                      \n",
      "2007-01-03  100.632450  16.735817  15.985817  0.000000   0.000000   0.0   \n",
      "2007-01-04  100.632450  17.195151  16.165149  0.000000   0.000000   0.0   \n",
      "2007-01-05  100.632450  17.088034  16.488035  0.000000   0.000000   0.0   \n",
      "2007-01-08  100.632450  16.770139  15.860139  0.000000   0.000000   0.0   \n",
      "2007-01-09  100.632450  17.562349  16.512349  0.000000   0.000000   0.0   \n",
      "...                ...        ...        ...       ...        ...   ...   \n",
      "2022-12-23   83.126924  -0.146384  -1.686385 -0.816813  46.068518   0.0   \n",
      "2022-12-27   83.126924   0.643523  -0.756478 -0.860545  46.068518   0.0   \n",
      "2022-12-28   83.126924   1.653096  -1.296901 -0.895187  45.085778   0.0   \n",
      "2022-12-29   83.126924   2.896219  -0.733786 -0.774089  45.085778   0.0   \n",
      "2022-12-30   83.126924   2.265731   0.895736 -0.617490  45.085778   0.0   \n",
      "\n",
      "                 qqes       ker  \n",
      "Date                             \n",
      "2007-01-03   0.000000  0.000000  \n",
      "2007-01-04   0.000000  1.000000  \n",
      "2007-01-05   0.000000  0.230673  \n",
      "2007-01-08   0.000000  0.098562  \n",
      "2007-01-09   0.000000  0.521480  \n",
      "...               ...       ...  \n",
      "2022-12-23  46.068518  0.384728  \n",
      "2022-12-27  46.068518  0.444612  \n",
      "2022-12-28  45.085778  0.823117  \n",
      "2022-12-29  45.085778  0.355393  \n",
      "2022-12-30  45.085778  0.232466  \n",
      "\n",
      "[4028 rows x 19 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BBWI_close</th>\n",
       "      <th>BBWI_volume</th>\n",
       "      <th>BBWI_open</th>\n",
       "      <th>BBWI_high</th>\n",
       "      <th>BBWI_low</th>\n",
       "      <th>BBWI_cci</th>\n",
       "      <th>BBWI_stochrsi</th>\n",
       "      <th>BBWI_mfi</th>\n",
       "      <th>BBWI_bop</th>\n",
       "      <th>BBWI_supertrend_ub</th>\n",
       "      <th>...</th>\n",
       "      <th>SWK_eribull</th>\n",
       "      <th>SWK_eribear</th>\n",
       "      <th>SWK_cti</th>\n",
       "      <th>SWK_qqe</th>\n",
       "      <th>SWK_qqel</th>\n",
       "      <th>SWK_qqes</th>\n",
       "      <th>SWK_ker</th>\n",
       "      <th>SWK_momentum</th>\n",
       "      <th>SWK_simple_moving_average</th>\n",
       "      <th>SWK_bollinger_bands</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-03</th>\n",
       "      <td>10.077240</td>\n",
       "      <td>9288633</td>\n",
       "      <td>24.252222</td>\n",
       "      <td>24.276476</td>\n",
       "      <td>23.540825</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-19.268623</td>\n",
       "      <td>66.506358</td>\n",
       "      <td>...</td>\n",
       "      <td>16.735817</td>\n",
       "      <td>15.985817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>9.317529</td>\n",
       "      <td>17476831</td>\n",
       "      <td>22.546482</td>\n",
       "      <td>22.756668</td>\n",
       "      <td>21.891672</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-15.293659</td>\n",
       "      <td>62.557732</td>\n",
       "      <td>...</td>\n",
       "      <td>17.195151</td>\n",
       "      <td>16.165149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>9.310719</td>\n",
       "      <td>9970096</td>\n",
       "      <td>21.980598</td>\n",
       "      <td>22.433306</td>\n",
       "      <td>21.147940</td>\n",
       "      <td>-68.036196</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-9.857021</td>\n",
       "      <td>61.706632</td>\n",
       "      <td>...</td>\n",
       "      <td>17.088034</td>\n",
       "      <td>16.488035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230673</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-08</th>\n",
       "      <td>9.130162</td>\n",
       "      <td>9207238</td>\n",
       "      <td>22.029102</td>\n",
       "      <td>22.465643</td>\n",
       "      <td>21.471302</td>\n",
       "      <td>-53.794416</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-12.972352</td>\n",
       "      <td>61.706632</td>\n",
       "      <td>...</td>\n",
       "      <td>16.770139</td>\n",
       "      <td>15.860139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098562</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-09</th>\n",
       "      <td>9.266431</td>\n",
       "      <td>10808659</td>\n",
       "      <td>21.843168</td>\n",
       "      <td>22.465643</td>\n",
       "      <td>21.827002</td>\n",
       "      <td>-33.004958</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-19.692958</td>\n",
       "      <td>61.706632</td>\n",
       "      <td>...</td>\n",
       "      <td>17.562349</td>\n",
       "      <td>16.512349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.521480</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>41.287590</td>\n",
       "      <td>2461500</td>\n",
       "      <td>40.330002</td>\n",
       "      <td>41.950001</td>\n",
       "      <td>40.150002</td>\n",
       "      <td>-26.952787</td>\n",
       "      <td>50.075568</td>\n",
       "      <td>0.271783</td>\n",
       "      <td>0.531994</td>\n",
       "      <td>46.013340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146384</td>\n",
       "      <td>-1.686385</td>\n",
       "      <td>-0.816813</td>\n",
       "      <td>46.068518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.068518</td>\n",
       "      <td>0.384728</td>\n",
       "      <td>0.935280</td>\n",
       "      <td>-0.054770</td>\n",
       "      <td>-0.699713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>41.297436</td>\n",
       "      <td>3022500</td>\n",
       "      <td>41.939999</td>\n",
       "      <td>42.889999</td>\n",
       "      <td>41.810001</td>\n",
       "      <td>46.300371</td>\n",
       "      <td>50.367960</td>\n",
       "      <td>0.338524</td>\n",
       "      <td>-0.594967</td>\n",
       "      <td>46.013340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643523</td>\n",
       "      <td>-0.756478</td>\n",
       "      <td>-0.860545</td>\n",
       "      <td>46.068518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.068518</td>\n",
       "      <td>0.444612</td>\n",
       "      <td>0.933509</td>\n",
       "      <td>-0.045928</td>\n",
       "      <td>-0.565087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>40.116104</td>\n",
       "      <td>2138000</td>\n",
       "      <td>41.779999</td>\n",
       "      <td>42.169998</td>\n",
       "      <td>40.630001</td>\n",
       "      <td>-29.822213</td>\n",
       "      <td>6.012631</td>\n",
       "      <td>0.345384</td>\n",
       "      <td>-1.080453</td>\n",
       "      <td>46.013340</td>\n",
       "      <td>...</td>\n",
       "      <td>1.653096</td>\n",
       "      <td>-1.296901</td>\n",
       "      <td>-0.895187</td>\n",
       "      <td>45.085778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.085778</td>\n",
       "      <td>0.823117</td>\n",
       "      <td>0.883260</td>\n",
       "      <td>-0.070031</td>\n",
       "      <td>-0.800777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>41.002102</td>\n",
       "      <td>1610500</td>\n",
       "      <td>41.349998</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>41.180000</td>\n",
       "      <td>15.208379</td>\n",
       "      <td>43.168234</td>\n",
       "      <td>0.393974</td>\n",
       "      <td>-0.424264</td>\n",
       "      <td>46.013340</td>\n",
       "      <td>...</td>\n",
       "      <td>2.896219</td>\n",
       "      <td>-0.733786</td>\n",
       "      <td>-0.774089</td>\n",
       "      <td>45.085778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.085778</td>\n",
       "      <td>0.355393</td>\n",
       "      <td>0.922133</td>\n",
       "      <td>-0.018299</td>\n",
       "      <td>-0.216329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>41.484478</td>\n",
       "      <td>2237000</td>\n",
       "      <td>41.099998</td>\n",
       "      <td>42.209999</td>\n",
       "      <td>40.880001</td>\n",
       "      <td>37.972594</td>\n",
       "      <td>62.418129</td>\n",
       "      <td>0.358997</td>\n",
       "      <td>0.289083</td>\n",
       "      <td>46.013340</td>\n",
       "      <td>...</td>\n",
       "      <td>2.265731</td>\n",
       "      <td>0.895736</td>\n",
       "      <td>-0.617490</td>\n",
       "      <td>45.085778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.085778</td>\n",
       "      <td>0.232466</td>\n",
       "      <td>0.916768</td>\n",
       "      <td>-0.023972</td>\n",
       "      <td>-0.299260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4028 rows Ã— 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            BBWI_close  BBWI_volume  BBWI_open  BBWI_high   BBWI_low  \\\n",
       "Date                                                                   \n",
       "2007-01-03   10.077240      9288633  24.252222  24.276476  23.540825   \n",
       "2007-01-04    9.317529     17476831  22.546482  22.756668  21.891672   \n",
       "2007-01-05    9.310719      9970096  21.980598  22.433306  21.147940   \n",
       "2007-01-08    9.130162      9207238  22.029102  22.465643  21.471302   \n",
       "2007-01-09    9.266431     10808659  21.843168  22.465643  21.827002   \n",
       "...                ...          ...        ...        ...        ...   \n",
       "2022-12-23   41.287590      2461500  40.330002  41.950001  40.150002   \n",
       "2022-12-27   41.297436      3022500  41.939999  42.889999  41.810001   \n",
       "2022-12-28   40.116104      2138000  41.779999  42.169998  40.630001   \n",
       "2022-12-29   41.002102      1610500  41.349998  42.000000  41.180000   \n",
       "2022-12-30   41.484478      2237000  41.099998  42.209999  40.880001   \n",
       "\n",
       "             BBWI_cci  BBWI_stochrsi  BBWI_mfi   BBWI_bop  BBWI_supertrend_ub  \\\n",
       "Date                                                                            \n",
       "2007-01-03 -66.666667     100.000000  0.500000 -19.268623           66.506358   \n",
       "2007-01-04 -66.666667     100.000000  0.500000 -15.293659           62.557732   \n",
       "2007-01-05 -68.036196     100.000000  0.500000  -9.857021           61.706632   \n",
       "2007-01-08 -53.794416     100.000000  0.500000 -12.972352           61.706632   \n",
       "2007-01-09 -33.004958     100.000000  0.500000 -19.692958           61.706632   \n",
       "...               ...            ...       ...        ...                 ...   \n",
       "2022-12-23 -26.952787      50.075568  0.271783   0.531994           46.013340   \n",
       "2022-12-27  46.300371      50.367960  0.338524  -0.594967           46.013340   \n",
       "2022-12-28 -29.822213       6.012631  0.345384  -1.080453           46.013340   \n",
       "2022-12-29  15.208379      43.168234  0.393974  -0.424264           46.013340   \n",
       "2022-12-30  37.972594      62.418129  0.358997   0.289083           46.013340   \n",
       "\n",
       "            ...  SWK_eribull  SWK_eribear   SWK_cti    SWK_qqe  SWK_qqel  \\\n",
       "Date        ...                                                            \n",
       "2007-01-03  ...    16.735817    15.985817  0.000000   0.000000       0.0   \n",
       "2007-01-04  ...    17.195151    16.165149  0.000000   0.000000       0.0   \n",
       "2007-01-05  ...    17.088034    16.488035  0.000000   0.000000       0.0   \n",
       "2007-01-08  ...    16.770139    15.860139  0.000000   0.000000       0.0   \n",
       "2007-01-09  ...    17.562349    16.512349  0.000000   0.000000       0.0   \n",
       "...         ...          ...          ...       ...        ...       ...   \n",
       "2022-12-23  ...    -0.146384    -1.686385 -0.816813  46.068518       0.0   \n",
       "2022-12-27  ...     0.643523    -0.756478 -0.860545  46.068518       0.0   \n",
       "2022-12-28  ...     1.653096    -1.296901 -0.895187  45.085778       0.0   \n",
       "2022-12-29  ...     2.896219    -0.733786 -0.774089  45.085778       0.0   \n",
       "2022-12-30  ...     2.265731     0.895736 -0.617490  45.085778       0.0   \n",
       "\n",
       "             SWK_qqes   SWK_ker  SWK_momentum  SWK_simple_moving_average  \\\n",
       "Date                                                                       \n",
       "2007-01-03   0.000000  0.000000      1.127609                   0.074881   \n",
       "2007-01-04   0.000000  1.000000      1.127609                   0.074881   \n",
       "2007-01-05   0.000000  0.230673      1.127609                   0.074881   \n",
       "2007-01-08   0.000000  0.098562      1.127609                   0.074881   \n",
       "2007-01-09   0.000000  0.521480      1.127609                   0.074881   \n",
       "...               ...       ...           ...                        ...   \n",
       "2022-12-23  46.068518  0.384728      0.935280                  -0.054770   \n",
       "2022-12-27  46.068518  0.444612      0.933509                  -0.045928   \n",
       "2022-12-28  45.085778  0.823117      0.883260                  -0.070031   \n",
       "2022-12-29  45.085778  0.355393      0.922133                  -0.018299   \n",
       "2022-12-30  45.085778  0.232466      0.916768                  -0.023972   \n",
       "\n",
       "            SWK_bollinger_bands  \n",
       "Date                             \n",
       "2007-01-03             1.098076  \n",
       "2007-01-04             1.098076  \n",
       "2007-01-05             1.098076  \n",
       "2007-01-08             1.098076  \n",
       "2007-01-09             1.098076  \n",
       "...                         ...  \n",
       "2022-12-23            -0.699713  \n",
       "2022-12-27            -0.565087  \n",
       "2022-12-28            -0.800777  \n",
       "2022-12-29            -0.216329  \n",
       "2022-12-30            -0.299260  \n",
       "\n",
       "[4028 rows x 220 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stockstats import StockDataFrame\n",
    "def extract_and_wrap_ticker_data(df, columns):\n",
    "    # Split column names into parts\n",
    "    parts = [col.split('_') for col in columns]\n",
    "\n",
    "    # Create a dictionary to store information about each ticker\n",
    "    ticker_info = {}\n",
    "\n",
    "    # Iterate through the parts list\n",
    "    for part in parts:\n",
    "        data_type = part[0]  # e.g., 'Adj Close', 'Close', etc.\n",
    "        ticker = part[1]     # e.g., 'AAPL', 'GOOGL', etc.\n",
    "\n",
    "        # Check if the ticker is already in the dictionary\n",
    "        if ticker not in ticker_info:\n",
    "            ticker_info[ticker] = {}\n",
    "\n",
    "        # Add information for the ticker\n",
    "        ticker_info[ticker][data_type] = df[f'{data_type}_{ticker}']\n",
    "\n",
    "    # Create a dictionary to store stockstats DataFrames for each ticker\n",
    "    ticker_dataframes = pd.DataFrame()\n",
    "#     var_importance_all=\n",
    "\n",
    "    # Iterate through ticker_info and wrap data with stockstats\n",
    "    for ticker, data in ticker_info.items():\n",
    "        print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "        df = pd.DataFrame(data)\n",
    "        print(ticker)\n",
    "#         print(df)\n",
    "        \n",
    "        stock_df = StockDataFrame.retype(df)\n",
    "        print(stock_df)\n",
    "\n",
    "\n",
    "#         stock_df[\"close\"] = stock_df[\"close\"].pct_change(1)\n",
    "#         stock_df=stock_df.dropna(subset=[\"close\"])\n",
    "#         print(stock_df)\n",
    "        \n",
    "#         stock_df['macds']=stock_df['macds']\n",
    "        stock_df['cci']=stock_df['cci']\n",
    "        stock_df['stochrsi']=stock_df['stochrsi']\n",
    "#         stock_df['ichimoku cloud']=stock_df['ichimoku cloud']\n",
    "        stock_df['mfi']=stock_df['mfi']\n",
    "        stock_df['bop']=stock_df['bop']\n",
    "        stock_df['supertrend']=stock_df['supertrend']\n",
    "        stock_df['eribull']=stock_df['eribull']\n",
    "        \n",
    "        stock_df['cti']=stock_df['cti']\n",
    "        stock_df['qqe']=stock_df['qqe']\n",
    "        stock_df['ker']=stock_df['ker']\n",
    "        print(stock_df)\n",
    "        roll_stat=rolling_statistics(stock_df,cols='close',\n",
    "                      window=20)\n",
    "        stock_df = pd.concat([stock_df,roll_stat],axis=1)\n",
    "\n",
    "\n",
    "#         print(stock_df)\n",
    "\n",
    "        stock_df.fillna(method='ffill',inplace=True)\n",
    "        stock_df.fillna(method='bfill',inplace=True)\n",
    "#         check_var_importance(stock_df)\n",
    "\n",
    "        print(\"*******************************\")\n",
    "\n",
    "        stock_df.columns = [ticker+\"_\" + col for col in pd.DataFrame(stock_df).columns]\n",
    "        ticker_dataframes = pd.concat([ticker_dataframes,stock_df],axis=1)\n",
    "        \n",
    "    return ticker_dataframes\n",
    "\n",
    "# Sample DataFrame with specified columns\n",
    "columns = list(df2.columns)\n",
    "\n",
    "\n",
    "\n",
    "# Extract and wrap ticker data\n",
    "ticker_dataframes = extract_and_wrap_ticker_data(df2, columns)\n",
    "\n",
    "# Access information for a specific ticker (e.g., AAPL)\n",
    "# print(ticker_dataframes)\n",
    "\n",
    "ticker_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edfe6dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            wti_spot  10y2y_spread  10y3m_spread  3m_rate  ltiit  ted_spread  \\\n",
      "Date                                                                           \n",
      "2007-01-02     60.77         -0.12         -0.39     4.94   2.33        0.42   \n",
      "2007-01-03     58.31         -0.09         -0.38     4.92   2.32        0.44   \n",
      "2007-01-04     55.65         -0.09         -0.42     4.91   2.30        0.45   \n",
      "2007-01-05     56.29         -0.11         -0.40     4.92   2.33        0.44   \n",
      "2007-01-08     56.08         -0.12         -0.42     4.95   2.34        0.41   \n",
      "...              ...           ...           ...      ...    ...         ...   \n",
      "2022-07-12       NaN         -0.07          0.74     2.16   1.12         NaN   \n",
      "2022-07-13       NaN         -0.22          0.52     2.33   1.06         NaN   \n",
      "2022-07-14       NaN         -0.19          0.56     2.33   1.07         NaN   \n",
      "2022-07-15       NaN         -0.20          0.56     2.29   1.03         NaN   \n",
      "2022-07-18       NaN         -0.19          0.46      NaN    NaN         NaN   \n",
      "\n",
      "             var_wti  \n",
      "Date                  \n",
      "2007-01-02       NaN  \n",
      "2007-01-03 -0.040481  \n",
      "2007-01-04 -0.045618  \n",
      "2007-01-05  0.011500  \n",
      "2007-01-08 -0.003731  \n",
      "...              ...  \n",
      "2022-07-12  0.000000  \n",
      "2022-07-13  0.000000  \n",
      "2022-07-14  0.000000  \n",
      "2022-07-15  0.000000  \n",
      "2022-07-18  0.000000  \n",
      "\n",
      "[3944 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the tickers\n",
    "new_tickers = ['EIA/PET_RWTC_D','FRED/T10Y2Y','FRED/T10Y3M','FRED/DTB3','FRED/DLTIIT','FRED/TEDRATE']\n",
    "\n",
    "# # Define the date range\n",
    "# start='2020-01-01'\n",
    "# end='2021-01-01'\n",
    "names = ['wti_spot','10y2y_spread','10y3m_spread','3m_rate','ltiit','ted_spread']\n",
    "# add_factors = quandl.get(tickers, start=start_date, end=end_date)\n",
    "\n",
    "# # Retrieve data\n",
    "data_quandl = quandl.get(new_tickers, start_date=start_date, end_date=end_date)\n",
    "data_quandl.columns = names\n",
    "data_quandl['var_wti'] = data_quandl['wti_spot'].pct_change()\n",
    "# print(data_quandl)\n",
    "\n",
    "# # Fill NaN values:\n",
    "# data_quandl.fillna(method='ffill',inplace=True)\n",
    "# data_quandl.fillna(method='bfill',inplace=True)\n",
    "\n",
    "\n",
    "# # Print the data\n",
    "print(data_quandl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1459bc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BBWI_close</th>\n",
       "      <th>BBWI_volume</th>\n",
       "      <th>BBWI_open</th>\n",
       "      <th>BBWI_high</th>\n",
       "      <th>BBWI_low</th>\n",
       "      <th>BBWI_cci</th>\n",
       "      <th>BBWI_stochrsi</th>\n",
       "      <th>BBWI_mfi</th>\n",
       "      <th>BBWI_bop</th>\n",
       "      <th>...</th>\n",
       "      <th>SWK_momentum</th>\n",
       "      <th>SWK_simple_moving_average</th>\n",
       "      <th>SWK_bollinger_bands</th>\n",
       "      <th>wti_spot</th>\n",
       "      <th>10y2y_spread</th>\n",
       "      <th>10y3m_spread</th>\n",
       "      <th>3m_rate</th>\n",
       "      <th>ltiit</th>\n",
       "      <th>ted_spread</th>\n",
       "      <th>var_wti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>10.077240</td>\n",
       "      <td>9288633</td>\n",
       "      <td>24.252222</td>\n",
       "      <td>24.276476</td>\n",
       "      <td>23.540825</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-19.268623</td>\n",
       "      <td>...</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "      <td>58.31</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>4.92</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-0.040481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>9.317529</td>\n",
       "      <td>17476831</td>\n",
       "      <td>22.546482</td>\n",
       "      <td>22.756668</td>\n",
       "      <td>21.891672</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-15.293659</td>\n",
       "      <td>...</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "      <td>55.65</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>4.91</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-0.045618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>9.310719</td>\n",
       "      <td>9970096</td>\n",
       "      <td>21.980598</td>\n",
       "      <td>22.433306</td>\n",
       "      <td>21.147940</td>\n",
       "      <td>-68.036196</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-9.857021</td>\n",
       "      <td>...</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "      <td>56.29</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>4.92</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.011500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-08</td>\n",
       "      <td>9.130162</td>\n",
       "      <td>9207238</td>\n",
       "      <td>22.029102</td>\n",
       "      <td>22.465643</td>\n",
       "      <td>21.471302</td>\n",
       "      <td>-53.794416</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-12.972352</td>\n",
       "      <td>...</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "      <td>56.08</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>4.95</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.003731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-09</td>\n",
       "      <td>9.266431</td>\n",
       "      <td>10808659</td>\n",
       "      <td>21.843168</td>\n",
       "      <td>22.465643</td>\n",
       "      <td>21.827002</td>\n",
       "      <td>-33.004958</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-19.692958</td>\n",
       "      <td>...</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "      <td>55.65</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>4.95</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.007668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>2022-07-12</td>\n",
       "      <td>26.133543</td>\n",
       "      <td>3131200</td>\n",
       "      <td>26.799999</td>\n",
       "      <td>27.610001</td>\n",
       "      <td>26.680000</td>\n",
       "      <td>-60.147031</td>\n",
       "      <td>71.722587</td>\n",
       "      <td>0.398109</td>\n",
       "      <td>-0.716619</td>\n",
       "      <td>...</td>\n",
       "      <td>1.013797</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>26.678598</td>\n",
       "      <td>3244200</td>\n",
       "      <td>26.450001</td>\n",
       "      <td>27.540001</td>\n",
       "      <td>26.080000</td>\n",
       "      <td>-57.069077</td>\n",
       "      <td>99.104455</td>\n",
       "      <td>0.413616</td>\n",
       "      <td>0.156574</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011707</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>0.141272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>2022-07-14</td>\n",
       "      <td>25.267288</td>\n",
       "      <td>4278500</td>\n",
       "      <td>26.870001</td>\n",
       "      <td>27.020000</td>\n",
       "      <td>25.809999</td>\n",
       "      <td>-93.255711</td>\n",
       "      <td>63.458053</td>\n",
       "      <td>0.423011</td>\n",
       "      <td>-1.324555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995777</td>\n",
       "      <td>-0.009406</td>\n",
       "      <td>-0.163278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>26.775932</td>\n",
       "      <td>4123700</td>\n",
       "      <td>26.459999</td>\n",
       "      <td>27.680000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>-34.397925</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.374416</td>\n",
       "      <td>0.220932</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053392</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.002596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3911</th>\n",
       "      <td>2022-07-18</td>\n",
       "      <td>27.817381</td>\n",
       "      <td>5343900</td>\n",
       "      <td>28.049999</td>\n",
       "      <td>29.480000</td>\n",
       "      <td>28.049999</td>\n",
       "      <td>138.383622</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.393358</td>\n",
       "      <td>-0.162670</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034479</td>\n",
       "      <td>-0.005507</td>\n",
       "      <td>-0.105373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3912 rows Ã— 228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  BBWI_close  BBWI_volume  BBWI_open  BBWI_high   BBWI_low  \\\n",
       "0    2007-01-03   10.077240      9288633  24.252222  24.276476  23.540825   \n",
       "1    2007-01-04    9.317529     17476831  22.546482  22.756668  21.891672   \n",
       "2    2007-01-05    9.310719      9970096  21.980598  22.433306  21.147940   \n",
       "3    2007-01-08    9.130162      9207238  22.029102  22.465643  21.471302   \n",
       "4    2007-01-09    9.266431     10808659  21.843168  22.465643  21.827002   \n",
       "...         ...         ...          ...        ...        ...        ...   \n",
       "3907 2022-07-12   26.133543      3131200  26.799999  27.610001  26.680000   \n",
       "3908 2022-07-13   26.678598      3244200  26.450001  27.540001  26.080000   \n",
       "3909 2022-07-14   25.267288      4278500  26.870001  27.020000  25.809999   \n",
       "3910 2022-07-15   26.775932      4123700  26.459999  27.680000  26.250000   \n",
       "3911 2022-07-18   27.817381      5343900  28.049999  29.480000  28.049999   \n",
       "\n",
       "        BBWI_cci  BBWI_stochrsi  BBWI_mfi   BBWI_bop  ...  SWK_momentum  \\\n",
       "0     -66.666667     100.000000  0.500000 -19.268623  ...      1.127609   \n",
       "1     -66.666667     100.000000  0.500000 -15.293659  ...      1.127609   \n",
       "2     -68.036196     100.000000  0.500000  -9.857021  ...      1.127609   \n",
       "3     -53.794416     100.000000  0.500000 -12.972352  ...      1.127609   \n",
       "4     -33.004958     100.000000  0.500000 -19.692958  ...      1.127609   \n",
       "...          ...            ...       ...        ...  ...           ...   \n",
       "3907  -60.147031      71.722587  0.398109  -0.716619  ...      1.013797   \n",
       "3908  -57.069077      99.104455  0.413616   0.156574  ...      1.011707   \n",
       "3909  -93.255711      63.458053  0.423011  -1.324555  ...      0.995777   \n",
       "3910  -34.397925     100.000000  0.374416   0.220932  ...      1.053392   \n",
       "3911  138.383622     100.000000  0.393358  -0.162670  ...      1.034479   \n",
       "\n",
       "      SWK_simple_moving_average  SWK_bollinger_bands  wti_spot  10y2y_spread  \\\n",
       "0                      0.074881             1.098076     58.31         -0.09   \n",
       "1                      0.074881             1.098076     55.65         -0.09   \n",
       "2                      0.074881             1.098076     56.29         -0.11   \n",
       "3                      0.074881             1.098076     56.08         -0.12   \n",
       "4                      0.074881             1.098076     55.65         -0.13   \n",
       "...                         ...                  ...       ...           ...   \n",
       "3907                   0.002237             0.038829       NaN         -0.07   \n",
       "3908                   0.008115             0.141272       NaN         -0.22   \n",
       "3909                  -0.009406            -0.163278       NaN         -0.19   \n",
       "3910                  -0.000149            -0.002596       NaN         -0.20   \n",
       "3911                  -0.005507            -0.105373       NaN         -0.19   \n",
       "\n",
       "      10y3m_spread  3m_rate  ltiit  ted_spread   var_wti  \n",
       "0            -0.38     4.92   2.32        0.44 -0.040481  \n",
       "1            -0.42     4.91   2.30        0.45 -0.045618  \n",
       "2            -0.40     4.92   2.33        0.44  0.011500  \n",
       "3            -0.42     4.95   2.34        0.41 -0.003731  \n",
       "4            -0.42     4.95   2.35        0.41 -0.007668  \n",
       "...            ...      ...    ...         ...       ...  \n",
       "3907          0.74     2.16   1.12         NaN  0.000000  \n",
       "3908          0.52     2.33   1.06         NaN  0.000000  \n",
       "3909          0.56     2.33   1.07         NaN  0.000000  \n",
       "3910          0.56     2.29   1.03         NaN  0.000000  \n",
       "3911          0.46      NaN    NaN         NaN  0.000000  \n",
       "\n",
       "[3912 rows x 228 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df=pd.merge(ticker_dataframes.reset_index(),data_quandl.reset_index(),on=['Date'],how='inner')\n",
    "# final_df=ticker_dataframes.copy()\n",
    "\n",
    "# Fill NaN values:\n",
    "# final_df.fillna(method='ffill',inplace=True)\n",
    "# final_df.fillna(method='bfill',inplace=True)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6053a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BBWI_close</th>\n",
       "      <th>BBWI_volume</th>\n",
       "      <th>BBWI_open</th>\n",
       "      <th>BBWI_high</th>\n",
       "      <th>BBWI_low</th>\n",
       "      <th>BBWI_cci</th>\n",
       "      <th>BBWI_stochrsi</th>\n",
       "      <th>BBWI_mfi</th>\n",
       "      <th>BBWI_bop</th>\n",
       "      <th>BBWI_supertrend_ub</th>\n",
       "      <th>...</th>\n",
       "      <th>SWK_ker</th>\n",
       "      <th>SWK_momentum</th>\n",
       "      <th>SWK_simple_moving_average</th>\n",
       "      <th>SWK_bollinger_bands</th>\n",
       "      <th>10y2y_spread</th>\n",
       "      <th>10y3m_spread</th>\n",
       "      <th>3m_rate</th>\n",
       "      <th>ltiit</th>\n",
       "      <th>ted_spread</th>\n",
       "      <th>var_wti</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-18</th>\n",
       "      <td>0.022359</td>\n",
       "      <td>4008127</td>\n",
       "      <td>22.667746</td>\n",
       "      <td>23.435732</td>\n",
       "      <td>22.554567</td>\n",
       "      <td>64.492999</td>\n",
       "      <td>97.164333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-14.764024</td>\n",
       "      <td>61.163117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807885</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>4.99</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.034226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-19</th>\n",
       "      <td>0.001411</td>\n",
       "      <td>4918559</td>\n",
       "      <td>22.441389</td>\n",
       "      <td>23.039612</td>\n",
       "      <td>22.384802</td>\n",
       "      <td>32.172866</td>\n",
       "      <td>98.183966</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-19.501156</td>\n",
       "      <td>61.163117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422506</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.029103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-22</th>\n",
       "      <td>-0.003522</td>\n",
       "      <td>4623906</td>\n",
       "      <td>23.282133</td>\n",
       "      <td>23.435732</td>\n",
       "      <td>22.772839</td>\n",
       "      <td>68.262820</td>\n",
       "      <td>95.794122</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-20.583045</td>\n",
       "      <td>61.163117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504289</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.016737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-23</th>\n",
       "      <td>-0.000707</td>\n",
       "      <td>4078018</td>\n",
       "      <td>22.691998</td>\n",
       "      <td>23.120453</td>\n",
       "      <td>22.675829</td>\n",
       "      <td>42.442574</td>\n",
       "      <td>95.294493</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-29.375478</td>\n",
       "      <td>61.163117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588108</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.048914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-24</th>\n",
       "      <td>0.001061</td>\n",
       "      <td>3377257</td>\n",
       "      <td>22.789005</td>\n",
       "      <td>23.088116</td>\n",
       "      <td>22.732416</td>\n",
       "      <td>64.123944</td>\n",
       "      <td>96.229060</td>\n",
       "      <td>0.466907</td>\n",
       "      <td>-36.963309</td>\n",
       "      <td>61.163117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536993</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.011752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-12</th>\n",
       "      <td>-0.002600</td>\n",
       "      <td>3131200</td>\n",
       "      <td>26.799999</td>\n",
       "      <td>27.610001</td>\n",
       "      <td>26.680000</td>\n",
       "      <td>-60.147031</td>\n",
       "      <td>71.722587</td>\n",
       "      <td>0.398109</td>\n",
       "      <td>-0.716619</td>\n",
       "      <td>32.801146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121495</td>\n",
       "      <td>1.013797</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-13</th>\n",
       "      <td>0.020857</td>\n",
       "      <td>3244200</td>\n",
       "      <td>26.450001</td>\n",
       "      <td>27.540001</td>\n",
       "      <td>26.080000</td>\n",
       "      <td>-57.069077</td>\n",
       "      <td>99.104455</td>\n",
       "      <td>0.413616</td>\n",
       "      <td>0.156574</td>\n",
       "      <td>32.374993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036593</td>\n",
       "      <td>1.011707</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>0.141272</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-14</th>\n",
       "      <td>-0.052900</td>\n",
       "      <td>4278500</td>\n",
       "      <td>26.870001</td>\n",
       "      <td>27.020000</td>\n",
       "      <td>25.809999</td>\n",
       "      <td>-93.255711</td>\n",
       "      <td>63.458053</td>\n",
       "      <td>0.423011</td>\n",
       "      <td>-1.324555</td>\n",
       "      <td>31.841779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.995777</td>\n",
       "      <td>-0.009406</td>\n",
       "      <td>-0.163278</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-15</th>\n",
       "      <td>0.059707</td>\n",
       "      <td>4123700</td>\n",
       "      <td>26.459999</td>\n",
       "      <td>27.680000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>-34.397925</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.374416</td>\n",
       "      <td>0.220932</td>\n",
       "      <td>31.841779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147882</td>\n",
       "      <td>1.053392</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.002596</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-18</th>\n",
       "      <td>0.038895</td>\n",
       "      <td>5343900</td>\n",
       "      <td>28.049999</td>\n",
       "      <td>29.480000</td>\n",
       "      <td>28.049999</td>\n",
       "      <td>138.383622</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.393358</td>\n",
       "      <td>-0.162670</td>\n",
       "      <td>31.841779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036254</td>\n",
       "      <td>1.034479</td>\n",
       "      <td>-0.005507</td>\n",
       "      <td>-0.105373</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3902 rows Ã— 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            BBWI_close  BBWI_volume  BBWI_open  BBWI_high   BBWI_low  \\\n",
       "Date                                                                   \n",
       "2007-01-18    0.022359      4008127  22.667746  23.435732  22.554567   \n",
       "2007-01-19    0.001411      4918559  22.441389  23.039612  22.384802   \n",
       "2007-01-22   -0.003522      4623906  23.282133  23.435732  22.772839   \n",
       "2007-01-23   -0.000707      4078018  22.691998  23.120453  22.675829   \n",
       "2007-01-24    0.001061      3377257  22.789005  23.088116  22.732416   \n",
       "...                ...          ...        ...        ...        ...   \n",
       "2022-07-12   -0.002600      3131200  26.799999  27.610001  26.680000   \n",
       "2022-07-13    0.020857      3244200  26.450001  27.540001  26.080000   \n",
       "2022-07-14   -0.052900      4278500  26.870001  27.020000  25.809999   \n",
       "2022-07-15    0.059707      4123700  26.459999  27.680000  26.250000   \n",
       "2022-07-18    0.038895      5343900  28.049999  29.480000  28.049999   \n",
       "\n",
       "              BBWI_cci  BBWI_stochrsi  BBWI_mfi   BBWI_bop  \\\n",
       "Date                                                         \n",
       "2007-01-18   64.492999      97.164333  0.500000 -14.764024   \n",
       "2007-01-19   32.172866      98.183966  0.500000 -19.501156   \n",
       "2007-01-22   68.262820      95.794122  0.500000 -20.583045   \n",
       "2007-01-23   42.442574      95.294493  0.500000 -29.375478   \n",
       "2007-01-24   64.123944      96.229060  0.466907 -36.963309   \n",
       "...                ...            ...       ...        ...   \n",
       "2022-07-12  -60.147031      71.722587  0.398109  -0.716619   \n",
       "2022-07-13  -57.069077      99.104455  0.413616   0.156574   \n",
       "2022-07-14  -93.255711      63.458053  0.423011  -1.324555   \n",
       "2022-07-15  -34.397925     100.000000  0.374416   0.220932   \n",
       "2022-07-18  138.383622     100.000000  0.393358  -0.162670   \n",
       "\n",
       "            BBWI_supertrend_ub  ...   SWK_ker  SWK_momentum  \\\n",
       "Date                            ...                           \n",
       "2007-01-18           61.163117  ...  0.807885      1.127609   \n",
       "2007-01-19           61.163117  ...  0.422506      1.127609   \n",
       "2007-01-22           61.163117  ...  0.504289      1.127609   \n",
       "2007-01-23           61.163117  ...  0.588108      1.127609   \n",
       "2007-01-24           61.163117  ...  0.536993      1.127609   \n",
       "...                        ...  ...       ...           ...   \n",
       "2022-07-12           32.801146  ...  0.121495      1.013797   \n",
       "2022-07-13           32.374993  ...  0.036593      1.011707   \n",
       "2022-07-14           31.841779  ...  0.001285      0.995777   \n",
       "2022-07-15           31.841779  ...  0.147882      1.053392   \n",
       "2022-07-18           31.841779  ...  0.036254      1.034479   \n",
       "\n",
       "            SWK_simple_moving_average  SWK_bollinger_bands  10y2y_spread  \\\n",
       "Date                                                                       \n",
       "2007-01-18                   0.074881             1.098076         -0.14   \n",
       "2007-01-19                   0.074881             1.098076         -0.15   \n",
       "2007-01-22                   0.074881             1.098076         -0.15   \n",
       "2007-01-23                   0.074881             1.098076         -0.13   \n",
       "2007-01-24                   0.074881             1.098076         -0.12   \n",
       "...                               ...                  ...           ...   \n",
       "2022-07-12                   0.002237             0.038829         -0.07   \n",
       "2022-07-13                   0.008115             0.141272         -0.22   \n",
       "2022-07-14                  -0.009406            -0.163278         -0.19   \n",
       "2022-07-15                  -0.000149            -0.002596         -0.20   \n",
       "2022-07-18                  -0.005507            -0.105373         -0.19   \n",
       "\n",
       "            10y3m_spread  3m_rate  ltiit  ted_spread   var_wti  \n",
       "Date                                                            \n",
       "2007-01-18         -0.37     4.99   2.41        0.37 -0.034226  \n",
       "2007-01-19         -0.36     5.01   2.42        0.35  0.029103  \n",
       "2007-01-22         -0.37     5.00   2.39        0.36 -0.016737  \n",
       "2007-01-23         -0.33     5.01   2.41        0.35  0.048914  \n",
       "2007-01-24         -0.32     5.00   2.39        0.36  0.011752  \n",
       "...                  ...      ...    ...         ...       ...  \n",
       "2022-07-12          0.74     2.16   1.12         NaN  0.000000  \n",
       "2022-07-13          0.52     2.33   1.06         NaN  0.000000  \n",
       "2022-07-14          0.56     2.33   1.07         NaN  0.000000  \n",
       "2022-07-15          0.56     2.29   1.03         NaN  0.000000  \n",
       "2022-07-18          0.46      NaN    NaN         NaN  0.000000  \n",
       "\n",
       "[3902 rows x 226 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df2=final_df.copy()\n",
    "for ticker in tickers:\n",
    "    final_df2[ticker+\"_close\"] = final_df2[ticker+\"_close\"].pct_change()\n",
    "#     final_df.drop(columns=[ticker+\"_adj close\"],inplace=True)\n",
    "    final_df2=final_df2.dropna(subset=[ticker+\"_close\"])\n",
    "final_df2.set_index(['Date'],inplace=True)\n",
    "final_df2.drop(columns=['wti_spot'],inplace=True)\n",
    "final_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e74cfd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def check_var_importance(df,ticker):\n",
    "    # Separate features (X) and target (y)\n",
    "    # AAPL_df.drop(columns=[\"AAPL_cr\"],inplace=True)\n",
    "    X = df  # Use relevant columns\n",
    "    y = df[ticker+'_close']  # Target variable is 'Close'\n",
    "\n",
    "    # Standardize features (optional but often recommended for neural networks)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Create sequences of length 5 for X and corresponding y for training\n",
    "    X_train, y_train = [], []\n",
    "\n",
    "    for i in range(5, len(X)):\n",
    "        X_train.append(X[i-5:i])\n",
    "        y_train.append(y[i])\n",
    "\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "#     print(X_train)\n",
    "#     print(\"***************\")\n",
    "#     print(y_train)\n",
    "\n",
    "    # Step 2: Check Variable Importance\n",
    "    # Use RandomForestRegressor to determine importance\n",
    "    rf = RandomForestRegressor(n_estimators=10)\n",
    "    rf.fit(X_train.reshape(-1, 5 * X.shape[1]), y_train)\n",
    "\n",
    "    # Get feature importances along with their corresponding feature names\n",
    "    feature_importances = rf.feature_importances_\n",
    "    feature_names = [col.split(ticker+\"_\")[-1] for col in df.columns]\n",
    "#     print(feature_names)\n",
    "\n",
    "    # Combine feature names with their importances\n",
    "    feature_importance_info = list(zip(feature_names, feature_importances))\n",
    "\n",
    "    # Sort the list by importance (in descending order)\n",
    "    feature_importance_info.sort(key=lambda x: x[0])\n",
    "\n",
    "    return pd.DataFrame(feature_importance_info,columns=['Features',ticker+'_Relative_Importance'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f98c310f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Features DIS_Relative_Importance BIIB_Relative_Importance  \\\n",
      "0         bollinger_bands                0.007557                 0.004856   \n",
      "1                     bop                0.011653                  0.03182   \n",
      "2                     cci                0.008363                 0.007719   \n",
      "3                   close                0.034204                 0.013267   \n",
      "4                     cti                0.008794                 0.012871   \n",
      "5                 eribear                0.008147                 0.006587   \n",
      "6                 eribull                0.011455                 0.013581   \n",
      "7                    high                0.002435                  0.00211   \n",
      "8                     ker                0.017369                 0.029807   \n",
      "9                     low                0.008065                 0.003702   \n",
      "10                    mfi                0.009141                 0.010346   \n",
      "11               momentum                0.021495                 0.014543   \n",
      "12                   open                0.010417                 0.003611   \n",
      "13                    qqe                0.003335                 0.004326   \n",
      "14                   qqel                0.004182                 0.002711   \n",
      "15                   qqes                0.003262                 0.004015   \n",
      "16  simple_moving_average                0.010107                 0.006631   \n",
      "17               stochrsi                 0.00469                 0.005879   \n",
      "18             supertrend                0.001048                 0.008534   \n",
      "19          supertrend_lb                0.003184                 0.004742   \n",
      "20          supertrend_ub                0.000575                 0.007367   \n",
      "21                 volume                0.012501                 0.015747   \n",
      "\n",
      "   GILD_Relative_Importance ETR_Relative_Importance PEP_Relative_Importance  \\\n",
      "0                   0.00875                0.013161                 0.00478   \n",
      "1                  0.013953                0.012883                0.011892   \n",
      "2                  0.011046                0.008388                 0.00904   \n",
      "3                  0.039138                0.041107                0.035387   \n",
      "4                   0.01104                0.011526                0.012486   \n",
      "5                  0.006005                0.005766                0.009232   \n",
      "6                  0.005838                0.009661                0.011735   \n",
      "7                  0.002811                 0.00341                0.001982   \n",
      "8                  0.012241                0.012905                0.010521   \n",
      "9                  0.003556                 0.00691                 0.00228   \n",
      "10                  0.01709                0.006368                0.010439   \n",
      "11                 0.012617                0.014131                0.014396   \n",
      "12                 0.004786                0.004783                0.003965   \n",
      "13                 0.010401                0.009777                0.006423   \n",
      "14                 0.004109                0.002718                0.004836   \n",
      "15                 0.009389                 0.00209                0.002841   \n",
      "16                 0.014485                0.018046                 0.01122   \n",
      "17                 0.007092                0.006912                0.005738   \n",
      "18                 0.000911                0.000644                 0.00151   \n",
      "19                 0.001897                0.000743                0.000812   \n",
      "20                 0.000683                0.000462                0.000434   \n",
      "21                 0.017103                 0.01362                0.014181   \n",
      "\n",
      "   NVDA_Relative_Importance NI_Relative_Importance BBWI_Relative_Importance  \\\n",
      "0                  0.008992               0.010797                 0.007997   \n",
      "1                  0.022989               0.012168                 0.012325   \n",
      "2                  0.007002               0.008452                  0.01206   \n",
      "3                  0.023124               0.026764                 0.011308   \n",
      "4                  0.009729               0.012572                 0.014595   \n",
      "5                  0.008656               0.005657                 0.004367   \n",
      "6                  0.009891               0.005319                 0.008775   \n",
      "7                  0.003862               0.002737                 0.004675   \n",
      "8                   0.01687               0.015233                 0.010974   \n",
      "9                  0.005471               0.001819                 0.006504   \n",
      "10                 0.011326               0.013196                 0.015629   \n",
      "11                 0.015228               0.018155                 0.008309   \n",
      "12                 0.003821                  0.005                 0.003774   \n",
      "13                 0.007526               0.004864                 0.007373   \n",
      "14                 0.003326               0.001506                 0.001697   \n",
      "15                 0.002921                0.00308                  0.00286   \n",
      "16                 0.007594               0.008582                 0.048639   \n",
      "17                 0.006409               0.007911                 0.003356   \n",
      "18                 0.001448               0.003259                 0.001792   \n",
      "19                 0.007301               0.001634                 0.001395   \n",
      "20                  0.00094               0.002373                 0.002712   \n",
      "21                 0.021132               0.009222                 0.014401   \n",
      "\n",
      "   SWK_Relative_Importance CBRE_Relative_Importance  \\\n",
      "0                  0.00649                 0.003583   \n",
      "1                 0.010508                 0.009906   \n",
      "2                 0.009575                 0.007296   \n",
      "3                 0.015404                 0.028826   \n",
      "4                 0.007887                 0.003479   \n",
      "5                 0.020037                 0.006546   \n",
      "6                 0.012813                 0.009418   \n",
      "7                 0.006379                  0.00516   \n",
      "8                 0.010998                 0.006405   \n",
      "9                 0.004502                  0.00176   \n",
      "10                0.008206                 0.006632   \n",
      "11                0.013934                 0.021457   \n",
      "12                0.006796                 0.006373   \n",
      "13                0.009057                 0.005002   \n",
      "14                0.001895                 0.001001   \n",
      "15                 0.00558                 0.001476   \n",
      "16                0.013824                  0.00549   \n",
      "17                 0.01019                 0.004949   \n",
      "18                0.005384                 0.005498   \n",
      "19                0.001242                  0.00524   \n",
      "20                0.001273                 0.002084   \n",
      "21                0.016127                 0.011431   \n",
      "\n",
      "    Average_relative_Importance  \n",
      "0                      0.007696  \n",
      "1                      0.015010  \n",
      "2                      0.008894  \n",
      "3                      0.026853  \n",
      "4                      0.010498  \n",
      "5                      0.008100  \n",
      "6                      0.009848  \n",
      "7                      0.003556  \n",
      "8                      0.014332  \n",
      "9                      0.004457  \n",
      "10                     0.010837  \n",
      "11                     0.015427  \n",
      "12                     0.005333  \n",
      "13                     0.006808  \n",
      "14                     0.002798  \n",
      "15                     0.003751  \n",
      "16                     0.014462  \n",
      "17                     0.006313  \n",
      "18                     0.003003  \n",
      "19                     0.002819  \n",
      "20                     0.001890  \n",
      "21                     0.014546  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>DIS_Relative_Importance</th>\n",
       "      <th>BIIB_Relative_Importance</th>\n",
       "      <th>GILD_Relative_Importance</th>\n",
       "      <th>ETR_Relative_Importance</th>\n",
       "      <th>PEP_Relative_Importance</th>\n",
       "      <th>NVDA_Relative_Importance</th>\n",
       "      <th>NI_Relative_Importance</th>\n",
       "      <th>BBWI_Relative_Importance</th>\n",
       "      <th>SWK_Relative_Importance</th>\n",
       "      <th>CBRE_Relative_Importance</th>\n",
       "      <th>Average_relative_Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bop</td>\n",
       "      <td>0.011653</td>\n",
       "      <td>0.03182</td>\n",
       "      <td>0.013953</td>\n",
       "      <td>0.012883</td>\n",
       "      <td>0.011892</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.012168</td>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.010508</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>0.015010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>close</td>\n",
       "      <td>0.034204</td>\n",
       "      <td>0.013267</td>\n",
       "      <td>0.039138</td>\n",
       "      <td>0.041107</td>\n",
       "      <td>0.035387</td>\n",
       "      <td>0.023124</td>\n",
       "      <td>0.026764</td>\n",
       "      <td>0.011308</td>\n",
       "      <td>0.015404</td>\n",
       "      <td>0.028826</td>\n",
       "      <td>0.026853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cti</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>0.012871</td>\n",
       "      <td>0.01104</td>\n",
       "      <td>0.011526</td>\n",
       "      <td>0.012486</td>\n",
       "      <td>0.009729</td>\n",
       "      <td>0.012572</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.010498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ker</td>\n",
       "      <td>0.017369</td>\n",
       "      <td>0.029807</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>0.012905</td>\n",
       "      <td>0.010521</td>\n",
       "      <td>0.01687</td>\n",
       "      <td>0.015233</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>0.010998</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>0.014332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mfi</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>0.010346</td>\n",
       "      <td>0.01709</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>0.010439</td>\n",
       "      <td>0.011326</td>\n",
       "      <td>0.013196</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.008206</td>\n",
       "      <td>0.006632</td>\n",
       "      <td>0.010837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>momentum</td>\n",
       "      <td>0.021495</td>\n",
       "      <td>0.014543</td>\n",
       "      <td>0.012617</td>\n",
       "      <td>0.014131</td>\n",
       "      <td>0.014396</td>\n",
       "      <td>0.015228</td>\n",
       "      <td>0.018155</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>0.021457</td>\n",
       "      <td>0.015427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>simple_moving_average</td>\n",
       "      <td>0.010107</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>0.014485</td>\n",
       "      <td>0.018046</td>\n",
       "      <td>0.01122</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>0.008582</td>\n",
       "      <td>0.048639</td>\n",
       "      <td>0.013824</td>\n",
       "      <td>0.00549</td>\n",
       "      <td>0.014462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>volume</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.015747</td>\n",
       "      <td>0.017103</td>\n",
       "      <td>0.01362</td>\n",
       "      <td>0.014181</td>\n",
       "      <td>0.021132</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>0.016127</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>0.014546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Features DIS_Relative_Importance BIIB_Relative_Importance  \\\n",
       "0                    bop                0.011653                  0.03182   \n",
       "1                  close                0.034204                 0.013267   \n",
       "2                    cti                0.008794                 0.012871   \n",
       "3                    ker                0.017369                 0.029807   \n",
       "4                    mfi                0.009141                 0.010346   \n",
       "5               momentum                0.021495                 0.014543   \n",
       "6  simple_moving_average                0.010107                 0.006631   \n",
       "7                 volume                0.012501                 0.015747   \n",
       "\n",
       "  GILD_Relative_Importance ETR_Relative_Importance PEP_Relative_Importance  \\\n",
       "0                 0.013953                0.012883                0.011892   \n",
       "1                 0.039138                0.041107                0.035387   \n",
       "2                  0.01104                0.011526                0.012486   \n",
       "3                 0.012241                0.012905                0.010521   \n",
       "4                  0.01709                0.006368                0.010439   \n",
       "5                 0.012617                0.014131                0.014396   \n",
       "6                 0.014485                0.018046                 0.01122   \n",
       "7                 0.017103                 0.01362                0.014181   \n",
       "\n",
       "  NVDA_Relative_Importance NI_Relative_Importance BBWI_Relative_Importance  \\\n",
       "0                 0.022989               0.012168                 0.012325   \n",
       "1                 0.023124               0.026764                 0.011308   \n",
       "2                 0.009729               0.012572                 0.014595   \n",
       "3                  0.01687               0.015233                 0.010974   \n",
       "4                 0.011326               0.013196                 0.015629   \n",
       "5                 0.015228               0.018155                 0.008309   \n",
       "6                 0.007594               0.008582                 0.048639   \n",
       "7                 0.021132               0.009222                 0.014401   \n",
       "\n",
       "  SWK_Relative_Importance CBRE_Relative_Importance  \\\n",
       "0                0.010508                 0.009906   \n",
       "1                0.015404                 0.028826   \n",
       "2                0.007887                 0.003479   \n",
       "3                0.010998                 0.006405   \n",
       "4                0.008206                 0.006632   \n",
       "5                0.013934                 0.021457   \n",
       "6                0.013824                  0.00549   \n",
       "7                0.016127                 0.011431   \n",
       "\n",
       "   Average_relative_Importance  \n",
       "0                     0.015010  \n",
       "1                     0.026853  \n",
       "2                     0.010498  \n",
       "3                     0.014332  \n",
       "4                     0.010837  \n",
       "5                     0.015427  \n",
       "6                     0.014462  \n",
       "7                     0.014546  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df2.head(2)\n",
    "feat_importance_all=pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "\n",
    "    matching_columns = [col for col in final_df2.columns if ticker in col]\n",
    "#     matching_columns.append([])\n",
    "    # # Print matching columns\n",
    "    # for col in matching_columns:\n",
    "    #     print(col)\n",
    "\n",
    "    temp_df=final_df2[matching_columns]\n",
    "    feat_importance_temp=check_var_importance(temp_df,ticker)\n",
    "    feat_importance_all=pd.concat([feat_importance_all,feat_importance_temp], axis=1)\n",
    "#     print(feat_importance_all)\n",
    "feat_importance_all=feat_importance_all.T.drop_duplicates(keep='first').T\n",
    "feat_importance_all[\"Average_relative_Importance\"]=feat_importance_all.iloc[:,1:].mean(axis=1)\n",
    "print(feat_importance_all)\n",
    "threshold = .01  # Example threshold value\n",
    "\n",
    "# Create a boolean mask based on the condition\n",
    "mask = feat_importance_all['Average_relative_Importance'] >= threshold\n",
    "\n",
    "# Apply the mask to the DataFrame\n",
    "filtered_df = feat_importance_all[mask]\n",
    "\n",
    "# df['Average_Columns'] = df[['Column1', 'Column2']].mean(axis=1)\n",
    "#     print(temp_df)\n",
    "\n",
    "filtered_df.reset_index(drop=True,inplace=True)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "385528f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BBWI_close</th>\n",
       "      <th>BBWI_volume</th>\n",
       "      <th>BBWI_open</th>\n",
       "      <th>BBWI_high</th>\n",
       "      <th>BBWI_low</th>\n",
       "      <th>BBWI_cci</th>\n",
       "      <th>BBWI_stochrsi</th>\n",
       "      <th>BBWI_mfi</th>\n",
       "      <th>BBWI_bop</th>\n",
       "      <th>BBWI_supertrend_ub</th>\n",
       "      <th>...</th>\n",
       "      <th>SWK_ker</th>\n",
       "      <th>SWK_momentum</th>\n",
       "      <th>SWK_simple_moving_average</th>\n",
       "      <th>SWK_bollinger_bands</th>\n",
       "      <th>10y2y_spread</th>\n",
       "      <th>10y3m_spread</th>\n",
       "      <th>3m_rate</th>\n",
       "      <th>ltiit</th>\n",
       "      <th>ted_spread</th>\n",
       "      <th>var_wti</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-18</th>\n",
       "      <td>0.022359</td>\n",
       "      <td>4008127</td>\n",
       "      <td>22.667746</td>\n",
       "      <td>23.435732</td>\n",
       "      <td>22.554567</td>\n",
       "      <td>64.492999</td>\n",
       "      <td>97.164333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-14.764024</td>\n",
       "      <td>61.163117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807885</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>4.99</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.034226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-19</th>\n",
       "      <td>0.001411</td>\n",
       "      <td>4918559</td>\n",
       "      <td>22.441389</td>\n",
       "      <td>23.039612</td>\n",
       "      <td>22.384802</td>\n",
       "      <td>32.172866</td>\n",
       "      <td>98.183966</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-19.501156</td>\n",
       "      <td>61.163117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422506</td>\n",
       "      <td>1.127609</td>\n",
       "      <td>0.074881</td>\n",
       "      <td>1.098076</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.029103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            BBWI_close  BBWI_volume  BBWI_open  BBWI_high   BBWI_low  \\\n",
       "Date                                                                   \n",
       "2007-01-18    0.022359      4008127  22.667746  23.435732  22.554567   \n",
       "2007-01-19    0.001411      4918559  22.441389  23.039612  22.384802   \n",
       "\n",
       "             BBWI_cci  BBWI_stochrsi  BBWI_mfi   BBWI_bop  BBWI_supertrend_ub  \\\n",
       "Date                                                                            \n",
       "2007-01-18  64.492999      97.164333       0.5 -14.764024           61.163117   \n",
       "2007-01-19  32.172866      98.183966       0.5 -19.501156           61.163117   \n",
       "\n",
       "            ...   SWK_ker  SWK_momentum  SWK_simple_moving_average  \\\n",
       "Date        ...                                                      \n",
       "2007-01-18  ...  0.807885      1.127609                   0.074881   \n",
       "2007-01-19  ...  0.422506      1.127609                   0.074881   \n",
       "\n",
       "            SWK_bollinger_bands  10y2y_spread  10y3m_spread  3m_rate  ltiit  \\\n",
       "Date                                                                          \n",
       "2007-01-18             1.098076         -0.14         -0.37     4.99   2.41   \n",
       "2007-01-19             1.098076         -0.15         -0.36     5.01   2.42   \n",
       "\n",
       "            ted_spread   var_wti  \n",
       "Date                              \n",
       "2007-01-18        0.37 -0.034226  \n",
       "2007-01-19        0.35  0.029103  \n",
       "\n",
       "[2 rows x 226 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "892e3ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DIS_bop', 'BIIB_bop', 'GILD_bop', 'ETR_bop', 'PEP_bop', 'NVDA_bop', 'NI_bop', 'BBWI_bop', 'SWK_bop', 'CBRE_bop', 'DIS_close', 'BIIB_close', 'GILD_close', 'ETR_close', 'PEP_close', 'NVDA_close', 'NI_close', 'BBWI_close', 'SWK_close', 'CBRE_close', 'DIS_cti', 'BIIB_cti', 'GILD_cti', 'ETR_cti', 'PEP_cti', 'NVDA_cti', 'NI_cti', 'BBWI_cti', 'SWK_cti', 'CBRE_cti', 'DIS_ker', 'BIIB_ker', 'GILD_ker', 'ETR_ker', 'PEP_ker', 'NVDA_ker', 'NI_ker', 'BBWI_ker', 'SWK_ker', 'CBRE_ker', 'DIS_mfi', 'BIIB_mfi', 'GILD_mfi', 'ETR_mfi', 'PEP_mfi', 'NVDA_mfi', 'NI_mfi', 'BBWI_mfi', 'SWK_mfi', 'CBRE_mfi', 'DIS_momentum', 'BIIB_momentum', 'GILD_momentum', 'ETR_momentum', 'PEP_momentum', 'NVDA_momentum', 'NI_momentum', 'BBWI_momentum', 'SWK_momentum', 'CBRE_momentum', 'DIS_simple_moving_average', 'BIIB_simple_moving_average', 'GILD_simple_moving_average', 'ETR_simple_moving_average', 'PEP_simple_moving_average', 'NVDA_simple_moving_average', 'NI_simple_moving_average', 'BBWI_simple_moving_average', 'SWK_simple_moving_average', 'CBRE_simple_moving_average', 'DIS_volume', 'BIIB_volume', 'GILD_volume', 'ETR_volume', 'PEP_volume', 'NVDA_volume', 'NI_volume', 'BBWI_volume', 'SWK_volume', 'CBRE_volume']\n"
     ]
    }
   ],
   "source": [
    "imp_col_names=[filtered_df['Features'].values][0].tolist()\n",
    "\n",
    "# imp_col_names = [ticker +\"_\"+ element for element in imp_col_names]\n",
    "final_col_names = []\n",
    "for col in imp_col_names:\n",
    "    for ticker in tickers:\n",
    "        final_col_names.append(f'{ticker}_{col}')\n",
    "\n",
    "print(final_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69c51193",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_col_names=final_col_names+['10y2y_spread','10y3m_spread','3m_rate','ltiit','ted_spread','var_wti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38092fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DIS_bop',\n",
       " 'BIIB_bop',\n",
       " 'GILD_bop',\n",
       " 'ETR_bop',\n",
       " 'PEP_bop',\n",
       " 'NVDA_bop',\n",
       " 'NI_bop',\n",
       " 'BBWI_bop',\n",
       " 'SWK_bop',\n",
       " 'CBRE_bop',\n",
       " 'DIS_close',\n",
       " 'BIIB_close',\n",
       " 'GILD_close',\n",
       " 'ETR_close',\n",
       " 'PEP_close',\n",
       " 'NVDA_close',\n",
       " 'NI_close',\n",
       " 'BBWI_close',\n",
       " 'SWK_close',\n",
       " 'CBRE_close',\n",
       " 'DIS_cti',\n",
       " 'BIIB_cti',\n",
       " 'GILD_cti',\n",
       " 'ETR_cti',\n",
       " 'PEP_cti',\n",
       " 'NVDA_cti',\n",
       " 'NI_cti',\n",
       " 'BBWI_cti',\n",
       " 'SWK_cti',\n",
       " 'CBRE_cti',\n",
       " 'DIS_ker',\n",
       " 'BIIB_ker',\n",
       " 'GILD_ker',\n",
       " 'ETR_ker',\n",
       " 'PEP_ker',\n",
       " 'NVDA_ker',\n",
       " 'NI_ker',\n",
       " 'BBWI_ker',\n",
       " 'SWK_ker',\n",
       " 'CBRE_ker',\n",
       " 'DIS_mfi',\n",
       " 'BIIB_mfi',\n",
       " 'GILD_mfi',\n",
       " 'ETR_mfi',\n",
       " 'PEP_mfi',\n",
       " 'NVDA_mfi',\n",
       " 'NI_mfi',\n",
       " 'BBWI_mfi',\n",
       " 'SWK_mfi',\n",
       " 'CBRE_mfi',\n",
       " 'DIS_momentum',\n",
       " 'BIIB_momentum',\n",
       " 'GILD_momentum',\n",
       " 'ETR_momentum',\n",
       " 'PEP_momentum',\n",
       " 'NVDA_momentum',\n",
       " 'NI_momentum',\n",
       " 'BBWI_momentum',\n",
       " 'SWK_momentum',\n",
       " 'CBRE_momentum',\n",
       " 'DIS_simple_moving_average',\n",
       " 'BIIB_simple_moving_average',\n",
       " 'GILD_simple_moving_average',\n",
       " 'ETR_simple_moving_average',\n",
       " 'PEP_simple_moving_average',\n",
       " 'NVDA_simple_moving_average',\n",
       " 'NI_simple_moving_average',\n",
       " 'BBWI_simple_moving_average',\n",
       " 'SWK_simple_moving_average',\n",
       " 'CBRE_simple_moving_average',\n",
       " 'DIS_volume',\n",
       " 'BIIB_volume',\n",
       " 'GILD_volume',\n",
       " 'ETR_volume',\n",
       " 'PEP_volume',\n",
       " 'NVDA_volume',\n",
       " 'NI_volume',\n",
       " 'BBWI_volume',\n",
       " 'SWK_volume',\n",
       " 'CBRE_volume',\n",
       " '10y2y_spread',\n",
       " '10y3m_spread',\n",
       " '3m_rate',\n",
       " 'ltiit',\n",
       " 'ted_spread',\n",
       " 'var_wti']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73f43ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIS_bop</th>\n",
       "      <th>BIIB_bop</th>\n",
       "      <th>GILD_bop</th>\n",
       "      <th>ETR_bop</th>\n",
       "      <th>PEP_bop</th>\n",
       "      <th>NVDA_bop</th>\n",
       "      <th>NI_bop</th>\n",
       "      <th>BBWI_bop</th>\n",
       "      <th>SWK_bop</th>\n",
       "      <th>CBRE_bop</th>\n",
       "      <th>...</th>\n",
       "      <th>NI_volume</th>\n",
       "      <th>BBWI_volume</th>\n",
       "      <th>SWK_volume</th>\n",
       "      <th>CBRE_volume</th>\n",
       "      <th>10y2y_spread</th>\n",
       "      <th>10y3m_spread</th>\n",
       "      <th>3m_rate</th>\n",
       "      <th>ltiit</th>\n",
       "      <th>ted_spread</th>\n",
       "      <th>var_wti</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-18</th>\n",
       "      <td>-7.662500</td>\n",
       "      <td>-0.367923</td>\n",
       "      <td>-9.698914</td>\n",
       "      <td>-68.917464</td>\n",
       "      <td>-18.312857</td>\n",
       "      <td>-1.731366</td>\n",
       "      <td>-38.002035</td>\n",
       "      <td>-14.764024</td>\n",
       "      <td>-7.766758</td>\n",
       "      <td>-0.503762</td>\n",
       "      <td>...</td>\n",
       "      <td>3706284</td>\n",
       "      <td>4008127</td>\n",
       "      <td>918600</td>\n",
       "      <td>1363900</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>4.99</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.034226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-19</th>\n",
       "      <td>-12.518892</td>\n",
       "      <td>0.476192</td>\n",
       "      <td>-12.176348</td>\n",
       "      <td>-42.831269</td>\n",
       "      <td>-73.043106</td>\n",
       "      <td>-1.491107</td>\n",
       "      <td>-39.868750</td>\n",
       "      <td>-19.501156</td>\n",
       "      <td>-20.102634</td>\n",
       "      <td>-0.661287</td>\n",
       "      <td>...</td>\n",
       "      <td>3921845</td>\n",
       "      <td>4918559</td>\n",
       "      <td>1044400</td>\n",
       "      <td>1318400</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.029103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-22</th>\n",
       "      <td>-13.832680</td>\n",
       "      <td>-0.926830</td>\n",
       "      <td>-10.789768</td>\n",
       "      <td>-28.542553</td>\n",
       "      <td>-41.459829</td>\n",
       "      <td>-3.119639</td>\n",
       "      <td>-41.165043</td>\n",
       "      <td>-20.583045</td>\n",
       "      <td>-20.188575</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>...</td>\n",
       "      <td>3585905</td>\n",
       "      <td>4623906</td>\n",
       "      <td>571700</td>\n",
       "      <td>1243300</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.016737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-23</th>\n",
       "      <td>-8.058037</td>\n",
       "      <td>-0.612716</td>\n",
       "      <td>-13.363525</td>\n",
       "      <td>-68.481319</td>\n",
       "      <td>-53.310003</td>\n",
       "      <td>-1.962927</td>\n",
       "      <td>-25.558623</td>\n",
       "      <td>-29.375478</td>\n",
       "      <td>-25.374418</td>\n",
       "      <td>0.593408</td>\n",
       "      <td>...</td>\n",
       "      <td>2448290</td>\n",
       "      <td>4078018</td>\n",
       "      <td>481400</td>\n",
       "      <td>1668600</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.048914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-24</th>\n",
       "      <td>-12.312811</td>\n",
       "      <td>-0.619717</td>\n",
       "      <td>-17.002267</td>\n",
       "      <td>-69.956119</td>\n",
       "      <td>-34.756463</td>\n",
       "      <td>-1.840543</td>\n",
       "      <td>-34.495851</td>\n",
       "      <td>-36.963309</td>\n",
       "      <td>-20.766541</td>\n",
       "      <td>0.661537</td>\n",
       "      <td>...</td>\n",
       "      <td>2247744</td>\n",
       "      <td>3377257</td>\n",
       "      <td>436800</td>\n",
       "      <td>2947300</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.011752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-12</th>\n",
       "      <td>0.010308</td>\n",
       "      <td>-0.238938</td>\n",
       "      <td>-3.179339</td>\n",
       "      <td>-2.074620</td>\n",
       "      <td>-2.045913</td>\n",
       "      <td>-0.360460</td>\n",
       "      <td>-2.009898</td>\n",
       "      <td>-0.716619</td>\n",
       "      <td>-1.373918</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>...</td>\n",
       "      <td>2643700</td>\n",
       "      <td>3131200</td>\n",
       "      <td>1738700</td>\n",
       "      <td>2029500</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-13</th>\n",
       "      <td>0.366072</td>\n",
       "      <td>0.589164</td>\n",
       "      <td>-1.616124</td>\n",
       "      <td>-3.021859</td>\n",
       "      <td>-1.174611</td>\n",
       "      <td>0.615636</td>\n",
       "      <td>-1.829128</td>\n",
       "      <td>0.156574</td>\n",
       "      <td>-0.471402</td>\n",
       "      <td>-0.047060</td>\n",
       "      <td>...</td>\n",
       "      <td>2505100</td>\n",
       "      <td>3244200</td>\n",
       "      <td>1380200</td>\n",
       "      <td>2285100</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-14</th>\n",
       "      <td>0.198891</td>\n",
       "      <td>0.269312</td>\n",
       "      <td>-3.690002</td>\n",
       "      <td>-1.284975</td>\n",
       "      <td>-0.856435</td>\n",
       "      <td>0.335622</td>\n",
       "      <td>-0.927322</td>\n",
       "      <td>-1.324555</td>\n",
       "      <td>-1.868440</td>\n",
       "      <td>0.836601</td>\n",
       "      <td>...</td>\n",
       "      <td>4172800</td>\n",
       "      <td>4278500</td>\n",
       "      <td>1071300</td>\n",
       "      <td>1995200</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-15</th>\n",
       "      <td>0.874042</td>\n",
       "      <td>0.454293</td>\n",
       "      <td>-2.022909</td>\n",
       "      <td>-2.724536</td>\n",
       "      <td>-2.026866</td>\n",
       "      <td>0.263157</td>\n",
       "      <td>-2.482117</td>\n",
       "      <td>0.220932</td>\n",
       "      <td>-2.093828</td>\n",
       "      <td>0.832001</td>\n",
       "      <td>...</td>\n",
       "      <td>3497500</td>\n",
       "      <td>4123700</td>\n",
       "      <td>848200</td>\n",
       "      <td>1831500</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-18</th>\n",
       "      <td>-0.336737</td>\n",
       "      <td>-0.562721</td>\n",
       "      <td>-2.003491</td>\n",
       "      <td>-4.383409</td>\n",
       "      <td>-2.493615</td>\n",
       "      <td>-0.240922</td>\n",
       "      <td>-3.189894</td>\n",
       "      <td>-0.162670</td>\n",
       "      <td>-2.032161</td>\n",
       "      <td>-0.459118</td>\n",
       "      <td>...</td>\n",
       "      <td>6041000</td>\n",
       "      <td>5343900</td>\n",
       "      <td>937500</td>\n",
       "      <td>1907700</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3902 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              DIS_bop  BIIB_bop   GILD_bop    ETR_bop    PEP_bop  NVDA_bop  \\\n",
       "Date                                                                         \n",
       "2007-01-18  -7.662500 -0.367923  -9.698914 -68.917464 -18.312857 -1.731366   \n",
       "2007-01-19 -12.518892  0.476192 -12.176348 -42.831269 -73.043106 -1.491107   \n",
       "2007-01-22 -13.832680 -0.926830 -10.789768 -28.542553 -41.459829 -3.119639   \n",
       "2007-01-23  -8.058037 -0.612716 -13.363525 -68.481319 -53.310003 -1.962927   \n",
       "2007-01-24 -12.312811 -0.619717 -17.002267 -69.956119 -34.756463 -1.840543   \n",
       "...               ...       ...        ...        ...        ...       ...   \n",
       "2022-07-12   0.010308 -0.238938  -3.179339  -2.074620  -2.045913 -0.360460   \n",
       "2022-07-13   0.366072  0.589164  -1.616124  -3.021859  -1.174611  0.615636   \n",
       "2022-07-14   0.198891  0.269312  -3.690002  -1.284975  -0.856435  0.335622   \n",
       "2022-07-15   0.874042  0.454293  -2.022909  -2.724536  -2.026866  0.263157   \n",
       "2022-07-18  -0.336737 -0.562721  -2.003491  -4.383409  -2.493615 -0.240922   \n",
       "\n",
       "               NI_bop   BBWI_bop    SWK_bop  CBRE_bop  ...  NI_volume  \\\n",
       "Date                                                   ...              \n",
       "2007-01-18 -38.002035 -14.764024  -7.766758 -0.503762  ...    3706284   \n",
       "2007-01-19 -39.868750 -19.501156 -20.102634 -0.661287  ...    3921845   \n",
       "2007-01-22 -41.165043 -20.583045 -20.188575  0.216669  ...    3585905   \n",
       "2007-01-23 -25.558623 -29.375478 -25.374418  0.593408  ...    2448290   \n",
       "2007-01-24 -34.495851 -36.963309 -20.766541  0.661537  ...    2247744   \n",
       "...               ...        ...        ...       ...  ...        ...   \n",
       "2022-07-12  -2.009898  -0.716619  -1.373918  0.641791  ...    2643700   \n",
       "2022-07-13  -1.829128   0.156574  -0.471402 -0.047060  ...    2505100   \n",
       "2022-07-14  -0.927322  -1.324555  -1.868440  0.836601  ...    4172800   \n",
       "2022-07-15  -2.482117   0.220932  -2.093828  0.832001  ...    3497500   \n",
       "2022-07-18  -3.189894  -0.162670  -2.032161 -0.459118  ...    6041000   \n",
       "\n",
       "            BBWI_volume  SWK_volume  CBRE_volume  10y2y_spread  10y3m_spread  \\\n",
       "Date                                                                           \n",
       "2007-01-18      4008127      918600      1363900         -0.14         -0.37   \n",
       "2007-01-19      4918559     1044400      1318400         -0.15         -0.36   \n",
       "2007-01-22      4623906      571700      1243300         -0.15         -0.37   \n",
       "2007-01-23      4078018      481400      1668600         -0.13         -0.33   \n",
       "2007-01-24      3377257      436800      2947300         -0.12         -0.32   \n",
       "...                 ...         ...          ...           ...           ...   \n",
       "2022-07-12      3131200     1738700      2029500         -0.07          0.74   \n",
       "2022-07-13      3244200     1380200      2285100         -0.22          0.52   \n",
       "2022-07-14      4278500     1071300      1995200         -0.19          0.56   \n",
       "2022-07-15      4123700      848200      1831500         -0.20          0.56   \n",
       "2022-07-18      5343900      937500      1907700         -0.19          0.46   \n",
       "\n",
       "            3m_rate  ltiit  ted_spread   var_wti  \n",
       "Date                                              \n",
       "2007-01-18     4.99   2.41        0.37 -0.034226  \n",
       "2007-01-19     5.01   2.42        0.35  0.029103  \n",
       "2007-01-22     5.00   2.39        0.36 -0.016737  \n",
       "2007-01-23     5.01   2.41        0.35  0.048914  \n",
       "2007-01-24     5.00   2.39        0.36  0.011752  \n",
       "...             ...    ...         ...       ...  \n",
       "2022-07-12     2.16   1.12         NaN  0.000000  \n",
       "2022-07-13     2.33   1.06         NaN  0.000000  \n",
       "2022-07-14     2.33   1.07         NaN  0.000000  \n",
       "2022-07-15     2.29   1.03         NaN  0.000000  \n",
       "2022-07-18      NaN    NaN         NaN  0.000000  \n",
       "\n",
       "[3902 rows x 86 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data=final_df2[final_col_names]\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df01faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    \"\"\"This class takes time series data that is in a sequential format, transforming\n",
    "    it into pairs of inputs and labels, so that the inputs are windows of consecutive\n",
    "    samples from the data.\n",
    "    \"\"\"\n",
    "    def __init__(self,input_width=5,label_width=1,shift=1, train_df=None, val_df=None,\n",
    "                 test_df=None, label_columns=None,batch_size=None,shuffle=False):\n",
    "        \"\"\"This method initiates the WindowGenerator class.\n",
    "\n",
    "        Inputs:\n",
    "        -------\n",
    "        input_width (int, default=5): the width of the window, which represents the \n",
    "            amount of time steps from the earliest input observation to the last.\n",
    "        label_width (int, default=1): the width of the label. This determines the amount\n",
    "             of time steps that will be predicted.\n",
    "        shift (int, default=1): jump between the last input in the window and the first \n",
    "            label.\n",
    "        train_df (pandas Dataframe, default=None): array-like object containing the train \n",
    "            data which comes in a time series format.\n",
    "        val_df (pandas Dataframe, default=None): array-like object containing the \n",
    "            validation data.\n",
    "        test_df (pandas Dataframe, default=None): array-like object containing the test \n",
    "            data.\n",
    "        label_columns (list|string, default=None): name of the column(s) that are used \n",
    "            as labels.\n",
    "        batch_size (int, deafault=None): the size of the batches of the tf.data.Dataset\n",
    "            object (whose dimensions are (batch,input_width,features) for the input and\n",
    "            (batch,label_width,label_columns) for the labels).\n",
    "        shuffle (boolean, default=False): determines if the data inside the tf.data.Dataset\n",
    "            is shuffled.\n",
    "        \n",
    "        Outputs:\n",
    "        --------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Define attributes of the class:\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        self.label_columns = label_columns\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Define information about columns:\n",
    "        if isinstance(label_columns,type(None)):\n",
    "            self.label_columns_indices = {name:i for i,name in enumerate(label_columns)}\n",
    "        self.column_indices = {name:i for i,name in enumerate(train_df.columns)}\n",
    "\n",
    "        # Define window information:\n",
    "        self.total_window_size = input_width+shift\n",
    "        self.input_slice = slice(0,input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size-self.label_width\n",
    "        self.labels_slice = slice(self.label_start,None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"This method determines what is returned when an instance of the object\n",
    "        is called\n",
    "        \"\"\"\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'\n",
    "        ])\n",
    "    \n",
    "    def split_window(self, features):\n",
    "        \"\"\"This method converts a list of consecutive inputs to a window of\n",
    "        inputs and a window of labels.\n",
    "\n",
    "        Inputs:\n",
    "        -------\n",
    "        features (pandas Dataset): features in the dataframe\n",
    "\n",
    "        Outputs:\n",
    "        --------\n",
    "        inputs ()\n",
    "        \"\"\"\n",
    "        inputs = features[:, self.input_slice,:]\n",
    "        labels = features[:,self.labels_slice,:]\n",
    "        if not isinstance(self.label_columns,type(None)):\n",
    "            labels = tf.stack(\n",
    "                [labels[:,:,self.column_indices[name]] for name in self.label_columns],\n",
    "                axis = -1\n",
    "            )\n",
    "        \n",
    "        # Set the shapes of the informaiton:\n",
    "        inputs.set_shape([None,self.input_width,None])\n",
    "        labels.set_shape([None,self.label_width,None])\n",
    "\n",
    "        return inputs,labels\n",
    "    \n",
    "    def make_dataset(self,data):\n",
    "        \"\"\"This method takes a time series DataFrame and convert it to a \n",
    "        tf.data.Dataset of (input_window,label_window) pairs, using the\n",
    "        tf.keras.preprocessing.timeseries_dataset_from_array function.\n",
    "\n",
    "        Input:\n",
    "        ------\n",
    "        data (pandas DataFrame): dataframe containing the time series information\n",
    "            of the inputs and labels, which will transformed into windows and then \n",
    "            a tf.Dataset object.\n",
    "        \n",
    "        Outputs:\n",
    "        --------\n",
    "\n",
    "        \"\"\"\n",
    "        data = np.array(data,dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "            data = data,\n",
    "            targets = None,\n",
    "            sequence_length = self.total_window_size,\n",
    "            sequence_stride = 1,\n",
    "            shuffle = self.shuffle,\n",
    "            batch_size = self.batch_size\n",
    "        )\n",
    "        ds = ds.map(self.split_window)\n",
    "        print(\"************************************************\")\n",
    "        print(ds)\n",
    "\n",
    "        return ds\n",
    "\n",
    "    # Adding properties for accessing the train, val and test as tf.data.Dataset objects\n",
    "    @property\n",
    "    def train(self):\n",
    "        if isinstance(self.train_df,type(None)):\n",
    "            return None\n",
    "        else:\n",
    "            return self.make_dataset(self.train_df)\n",
    "        print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")    \n",
    "        print(self.train_df)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        if isinstance(self.val_df,type(None)):\n",
    "            return None\n",
    "        else:\n",
    "            return self.make_dataset(self.val_df)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        if isinstance(self.test_df,type(None)):\n",
    "            return None\n",
    "        else:\n",
    "            return self.make_dataset(self.test_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e78a5a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DIS_close', 'BIIB_close', 'GILD_close', 'ETR_close', 'PEP_close', 'NVDA_close', 'NI_close', 'BBWI_close', 'SWK_close', 'CBRE_close']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dk/mxqr91nj7135zkb7ptp3mq5c0000gn/T/ipykernel_13106/3367714174.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_data.fillna(method='ffill',inplace=True)\n",
      "/var/folders/dk/mxqr91nj7135zkb7ptp3mq5c0000gn/T/ipykernel_13106/3367714174.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_data.fillna(method='bfill',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Define the label columns:\n",
    "\n",
    "# total_df=final_df2.copy()\n",
    "# total_df.set_index('Date',inplace=True)\n",
    "# label_cols = list(total_df.columns)\n",
    "# label_cols=label_cols[:len(tickers)]\n",
    "\n",
    "\n",
    "\n",
    "# matching_columns = [col for col in df.columns if \"close\" in col]\n",
    "model_data.fillna(method='ffill',inplace=True)\n",
    "model_data.fillna(method='bfill',inplace=True)\n",
    "\n",
    "model_data\n",
    "    \n",
    "label_cols=[col for col in model_data.columns if \"close\" in col]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# ['AAPL_returns', 'GOOGL_returns', 'MSFT_returns', 'SPY_returns']\n",
    "print(label_cols)\n",
    "\n",
    "# Define train (70%), val (20%) and test (10%) dataframes: \n",
    "train_p, val_p, test_p = 0.7,0.2,0.1\n",
    "window_size = 5\n",
    "num_features = model_data.shape[1]\n",
    "total_size = len(model_data)\n",
    "train_size = int(total_size*train_p)\n",
    "val_size = int(total_size*val_p)\n",
    "test_size = int(total_size*test_p)\n",
    "train_df = model_data.iloc[:train_size,:]\n",
    "val_df = model_data.iloc[train_size-window_size:train_size+val_size,:]\n",
    "test_df = model_data.iloc[train_size+val_size-window_size:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d6d6506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DIS_bop', 'BIIB_bop', 'GILD_bop', 'ETR_bop', 'PEP_bop', 'NVDA_bop',\n",
       "       'NI_bop', 'BBWI_bop', 'SWK_bop', 'CBRE_bop', 'DIS_close', 'BIIB_close',\n",
       "       'GILD_close', 'ETR_close', 'PEP_close', 'NVDA_close', 'NI_close',\n",
       "       'BBWI_close', 'SWK_close', 'CBRE_close', 'DIS_cti', 'BIIB_cti',\n",
       "       'GILD_cti', 'ETR_cti', 'PEP_cti', 'NVDA_cti', 'NI_cti', 'BBWI_cti',\n",
       "       'SWK_cti', 'CBRE_cti', 'DIS_ker', 'BIIB_ker', 'GILD_ker', 'ETR_ker',\n",
       "       'PEP_ker', 'NVDA_ker', 'NI_ker', 'BBWI_ker', 'SWK_ker', 'CBRE_ker',\n",
       "       'DIS_mfi', 'BIIB_mfi', 'GILD_mfi', 'ETR_mfi', 'PEP_mfi', 'NVDA_mfi',\n",
       "       'NI_mfi', 'BBWI_mfi', 'SWK_mfi', 'CBRE_mfi', 'DIS_momentum',\n",
       "       'BIIB_momentum', 'GILD_momentum', 'ETR_momentum', 'PEP_momentum',\n",
       "       'NVDA_momentum', 'NI_momentum', 'BBWI_momentum', 'SWK_momentum',\n",
       "       'CBRE_momentum', 'DIS_simple_moving_average',\n",
       "       'BIIB_simple_moving_average', 'GILD_simple_moving_average',\n",
       "       'ETR_simple_moving_average', 'PEP_simple_moving_average',\n",
       "       'NVDA_simple_moving_average', 'NI_simple_moving_average',\n",
       "       'BBWI_simple_moving_average', 'SWK_simple_moving_average',\n",
       "       'CBRE_simple_moving_average', 'DIS_volume', 'BIIB_volume',\n",
       "       'GILD_volume', 'ETR_volume', 'PEP_volume', 'NVDA_volume', 'NI_volume',\n",
       "       'BBWI_volume', 'SWK_volume', 'CBRE_volume', '10y2y_spread',\n",
       "       '10y3m_spread', '3m_rate', 'ltiit', 'ted_spread', 'var_wti'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f587865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2af088d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total window size: 6\n",
      "Input indices: [0 1 2 3 4]\n",
      "Label indices: [5]\n",
      "Label column name(s): ['DIS_close', 'BIIB_close', 'GILD_close', 'ETR_close', 'PEP_close', 'NVDA_close', 'NI_close', 'BBWI_close', 'SWK_close', 'CBRE_close']\n",
      "************************************************\n",
      "<_MapDataset element_spec=(TensorSpec(shape=(None, 5, 86), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 10), dtype=tf.float32, name=None))>\n",
      "Train input shape: (512, 5, 86)\n",
      "Train target shape: (512, 1, 10)\n",
      "************************************************\n",
      "<_MapDataset element_spec=(TensorSpec(shape=(None, 5, 86), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 10), dtype=tf.float32, name=None))>\n",
      "Validation input shape: (512, 5, 86)\n",
      "Validation target shape: (512, 1, 10)\n",
      "************************************************\n",
      "<_MapDataset element_spec=(TensorSpec(shape=(None, 5, 86), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 10), dtype=tf.float32, name=None))>\n",
      "Test input shape: (391, 5, 86)\n",
      "Test target shape: (391, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "# Define the batch size:\n",
    "batch_size = 512\n",
    "\n",
    "# Create an instance of the WindowGenerator object:\n",
    "my_window = WindowGenerator(input_width=window_size,label_width=1,shift=1,train_df=train_df,val_df=val_df,\n",
    "                            test_df=test_df,label_columns=label_cols,\n",
    "                            batch_size=batch_size,shuffle=True)\n",
    "print(my_window)\n",
    "\n",
    "# Print the shapes for one batch of each sub dataset:\n",
    "for example_inputs, example_labels in my_window.train.take(1):\n",
    "    print(\"Train input shape:\",example_inputs.shape)\n",
    "    print(\"Train target shape:\",example_labels.shape)\n",
    "for example_inputs, example_labels in my_window.val.take(1):\n",
    "    print(\"Validation input shape:\",example_inputs.shape)\n",
    "    print(\"Validation target shape:\",example_labels.shape)\n",
    "for example_inputs, example_labels in my_window.test.take(1):\n",
    "    print(\"Test input shape:\",example_inputs.shape)\n",
    "    print(\"Test target shape:\",example_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5edca84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# def initial_eda(dataset):\n",
    "#     for batch in dataset.take(1):  # Assuming you want to analyze the first batch\n",
    "#         print(\"Dimensions:\", batch[0].shape[0], \"samples,\", batch[0].shape[1], \"features\")\n",
    "#         print(\"Labels shape:\", batch[1].shape)\n",
    "#         print(\"Labels sample:\", batch[1].numpy()[:5])  # Printing first 5 labels as an example\n",
    "#         print(\"Features sample:\", batch[0].numpy()[:5])\n",
    "#         print(\"dataframe of the features\")\n",
    "#         print(pd.DataFrame(batch[0].numpy()[:5]))\n",
    "# # Assuming my_window.train is your TensorFlow dataset\n",
    "# initial_eda(my_window.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ac977e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c14a5c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Dense, Conv1D, LSTM, GRU, Input, BatchNormalization\n",
    "# from tensorflow.keras.models import Model, Sequential\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# # Model architecture creation:\n",
    "# model_1 = Sequential([\n",
    "#     BatchNormalization(\n",
    "#         input_shape = (window_size,num_features),\n",
    "#         name = 'Batch_Norm_1'),\n",
    "#     LSTM(512,return_sequences=True,name='LSTM_1'),\n",
    "# #    BatchNormalization(),\n",
    "#     LSTM(512,name='LSTM_2'),\n",
    "# #    BatchNormalization(momentum=0.8),\n",
    "#     Dense(256,activation='relu',name='Dense_1'),\n",
    "#     Dense(len(tickers),name='Returns')\n",
    "# ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# # Define an early stopping callback chatgpt\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_loss',  # Monitor validation loss\n",
    "#     patience=10,          # Stop training after no improvement for 10 epochs\n",
    "#     restore_best_weights=True,  # Restore the best weights when stopping\n",
    "# min_delta=0.0001)\n",
    "\n",
    "# # Checkpoint callback to save the model:\n",
    "# checkpont_rnn = ModelCheckpoint(\n",
    "#     filepath='model_inder_rnn2',\n",
    "#     save_weights_only=False,\n",
    "#     save_freq = 'epoch',\n",
    "#     monitor = 'val_loss',\n",
    "#     save_best_only = True,\n",
    "#     verbose = 1)\n",
    "\n",
    "\n",
    "# # # Learning Rate Schedule: used to decide the learning rate:\n",
    "# # lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "# #                 lambda epoch: 1e-8*10**(epoch/20))\n",
    "\n",
    "# # Define optimizer\n",
    "# optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
    "# # optimizer = tf.keras.optimizers.Adam(lr=lr_schedule)\n",
    "\n",
    "# # Compile Model\n",
    "# model_1.compile(\n",
    "#     loss=tf.keras.losses.Huber(),\n",
    "#     metrics=[tf.metrics.RootMeanSquaredError(),'mae'],\n",
    "#     optimizer=optimizer)\n",
    "\n",
    "# # # Train model\n",
    "# # history = model_1.fit(\n",
    "# #     my_window.train,\n",
    "# #     validation_data=my_window.val,\n",
    "# #     epochs=100)\n",
    "\n",
    "# # During model training, include both callbacks *********CHATGPT\n",
    "# history = model_1.fit(\n",
    "#     my_window.train,\n",
    "#     epochs=100,\n",
    "#     validation_data=my_window.val,\n",
    "#     callbacks=[early_stopping, checkpont_rnn]\n",
    "# )\n",
    "# model_1.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ae8e83f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************\n",
      "<_MapDataset element_spec=(TensorSpec(shape=(None, 5, 86), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 10), dtype=tf.float32, name=None))>\n",
      "************************************************\n",
      "<_MapDataset element_spec=(TensorSpec(shape=(None, 5, 86), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 10), dtype=tf.float32, name=None))>\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1255 - root_mean_squared_error: 0.5683 - mae: 0.3165[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>]\n",
      "Epoch 1: Learning Rate = 0.009999999776482582, Loss = 0.1254698634147644\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00698, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 5s 641ms/step - loss: 0.1255 - root_mean_squared_error: 0.5683 - mae: 0.3165 - val_loss: 0.0070 - val_root_mean_squared_error: 0.1180 - val_mae: 0.0877 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0064 - root_mean_squared_error: 0.1150 - mae: 0.0608[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.009>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.009>]\n",
      "Epoch 2: Learning Rate = 0.008999999612569809, Loss = 0.006389408838003874\n",
      "\n",
      "Epoch 2: val_loss improved from 0.00698 to 0.00146, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 558ms/step - loss: 0.0064 - root_mean_squared_error: 0.1150 - mae: 0.0608 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0536 - val_mae: 0.0364 - lr: 0.0090\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 4.2517e-04 - root_mean_squared_error: 0.0292 - mae: 0.0207[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0081>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0081>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0081>]\n",
      "Epoch 3: Learning Rate = 0.008100000210106373, Loss = 0.00042517148540355265\n",
      "\n",
      "Epoch 3: val_loss improved from 0.00146 to 0.00048, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 549ms/step - loss: 4.2517e-04 - root_mean_squared_error: 0.0292 - mae: 0.0207 - val_loss: 4.7577e-04 - val_root_mean_squared_error: 0.0312 - val_mae: 0.0206 - lr: 0.0081\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 3.1287e-04 - root_mean_squared_error: 0.0250 - mae: 0.0168[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00729>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00729>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00729>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00729>]\n",
      "Epoch 4: Learning Rate = 0.007290000095963478, Loss = 0.00031286553712561727\n",
      "\n",
      "Epoch 4: val_loss improved from 0.00048 to 0.00037, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 565ms/step - loss: 3.1287e-04 - root_mean_squared_error: 0.0250 - mae: 0.0168 - val_loss: 3.7308e-04 - val_root_mean_squared_error: 0.0270 - val_mae: 0.0168 - lr: 0.0073\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.7241e-04 - root_mean_squared_error: 0.0233 - mae: 0.0148[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.006561>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.006561>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.006561>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.006561>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.006561>]\n",
      "Epoch 5: Learning Rate = 0.006560999900102615, Loss = 0.0002724082150962204\n",
      "\n",
      "Epoch 5: val_loss improved from 0.00037 to 0.00035, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 553ms/step - loss: 2.7241e-04 - root_mean_squared_error: 0.0233 - mae: 0.0148 - val_loss: 3.5326e-04 - val_root_mean_squared_error: 0.0269 - val_mae: 0.0158 - lr: 0.0066\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.6320e-04 - root_mean_squared_error: 0.0230 - mae: 0.0142[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0059049>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0059049>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0059049>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0059049>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0059049>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0059049>]\n",
      "Epoch 6: Learning Rate = 0.005904899910092354, Loss = 0.0002632028190419078\n",
      "\n",
      "Epoch 6: val_loss improved from 0.00035 to 0.00035, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 519ms/step - loss: 2.6320e-04 - root_mean_squared_error: 0.0230 - mae: 0.0142 - val_loss: 3.5087e-04 - val_root_mean_squared_error: 0.0264 - val_mae: 0.0156 - lr: 0.0059\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.6279e-04 - root_mean_squared_error: 0.0230 - mae: 0.0142[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00531441>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00531441>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00531441>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00531441>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00531441>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00531441>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00531441>]\n",
      "Epoch 7: Learning Rate = 0.005314410198479891, Loss = 0.0002627891954034567\n",
      "\n",
      "Epoch 7: val_loss improved from 0.00035 to 0.00035, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 557ms/step - loss: 2.6279e-04 - root_mean_squared_error: 0.0230 - mae: 0.0142 - val_loss: 3.4979e-04 - val_root_mean_squared_error: 0.0262 - val_mae: 0.0156 - lr: 0.0053\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.6186e-04 - root_mean_squared_error: 0.0230 - mae: 0.0142[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004782969>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004782969>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004782969>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004782969>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004782969>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004782969>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004782969>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004782969>]\n",
      "Epoch 8: Learning Rate = 0.004782969132065773, Loss = 0.00026186410104855895\n",
      "\n",
      "Epoch 8: val_loss improved from 0.00035 to 0.00035, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 565ms/step - loss: 2.6186e-04 - root_mean_squared_error: 0.0230 - mae: 0.0142 - val_loss: 3.4787e-04 - val_root_mean_squared_error: 0.0261 - val_mae: 0.0155 - lr: 0.0048\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.6034e-04 - root_mean_squared_error: 0.0229 - mae: 0.0141[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004304672>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004304672>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004304672>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004304672>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004304672>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004304672>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004304672>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004304672>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004304672>]\n",
      "Epoch 9: Learning Rate = 0.004304672125726938, Loss = 0.0002603436296340078\n",
      "\n",
      "Epoch 9: val_loss improved from 0.00035 to 0.00035, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 518ms/step - loss: 2.6034e-04 - root_mean_squared_error: 0.0229 - mae: 0.0141 - val_loss: 3.4657e-04 - val_root_mean_squared_error: 0.0266 - val_mae: 0.0156 - lr: 0.0043\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.5930e-04 - root_mean_squared_error: 0.0229 - mae: 0.0140[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0038742048>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0038742048>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0038742048>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0038742048>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0038742048>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0038742048>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0038742048>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0038742048>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0038742048>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0038742048>]\n",
      "Epoch 10: Learning Rate = 0.003874204820021987, Loss = 0.00025929659022949636\n",
      "\n",
      "Epoch 10: val_loss improved from 0.00035 to 0.00035, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 553ms/step - loss: 2.5930e-04 - root_mean_squared_error: 0.0229 - mae: 0.0140 - val_loss: 3.4594e-04 - val_root_mean_squared_error: 0.0253 - val_mae: 0.0151 - lr: 0.0039\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.5882e-04 - root_mean_squared_error: 0.0228 - mae: 0.0139[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0034867844>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0034867844>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0034867844>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0034867844>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0034867844>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0034867844>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0034867844>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0034867844>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0034867844>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0034867844>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0034867844>]\n",
      "Epoch 11: Learning Rate = 0.0034867844078689814, Loss = 0.0002588236820884049\n",
      "\n",
      "Epoch 11: val_loss improved from 0.00035 to 0.00035, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 556ms/step - loss: 2.5882e-04 - root_mean_squared_error: 0.0228 - mae: 0.0139 - val_loss: 3.4561e-04 - val_root_mean_squared_error: 0.0261 - val_mae: 0.0154 - lr: 0.0035\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.5855e-04 - root_mean_squared_error: 0.0227 - mae: 0.0139[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0031381059>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0031381059>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0031381059>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0031381059>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0031381059>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0031381059>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0031381059>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0031381059>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0031381059>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0031381059>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0031381059>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0031381059>]\n",
      "Epoch 12: Learning Rate = 0.0031381058506667614, Loss = 0.00025855100830085576\n",
      "\n",
      "Epoch 12: val_loss improved from 0.00035 to 0.00035, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 549ms/step - loss: 2.5855e-04 - root_mean_squared_error: 0.0227 - mae: 0.0139 - val_loss: 3.4549e-04 - val_root_mean_squared_error: 0.0263 - val_mae: 0.0154 - lr: 0.0031\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.5850e-04 - root_mean_squared_error: 0.0227 - mae: 0.0139[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0028242953>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0028242953>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0028242953>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0028242953>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0028242953>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0028242953>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0028242953>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0028242953>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0028242953>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0028242953>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0028242953>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0028242953>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0028242953>]\n",
      "Epoch 13: Learning Rate = 0.002824295312166214, Loss = 0.00025850211386568844\n",
      "\n",
      "Epoch 13: val_loss improved from 0.00035 to 0.00035, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 532ms/step - loss: 2.5850e-04 - root_mean_squared_error: 0.0227 - mae: 0.0139 - val_loss: 3.4540e-04 - val_root_mean_squared_error: 0.0262 - val_mae: 0.0155 - lr: 0.0028\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.5850e-04 - root_mean_squared_error: 0.0228 - mae: 0.0139[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002541866>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002541866>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002541866>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002541866>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002541866>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002541866>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002541866>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002541866>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002541866>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002541866>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002541866>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002541866>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002541866>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002541866>]\n",
      "Epoch 14: Learning Rate = 0.0025418659206479788, Loss = 0.0002585037727840245\n",
      "\n",
      "Epoch 14: val_loss improved from 0.00035 to 0.00035, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 556ms/step - loss: 2.5850e-04 - root_mean_squared_error: 0.0228 - mae: 0.0139 - val_loss: 3.4533e-04 - val_root_mean_squared_error: 0.0260 - val_mae: 0.0153 - lr: 0.0025\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.5850e-04 - root_mean_squared_error: 0.0227 - mae: 0.0139[<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>, <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022876794>]\n",
      "Epoch 15: Learning Rate = 0.0022876793518662453, Loss = 0.00025849658413790166\n",
      "\n",
      "Epoch 15: val_loss improved from 0.00035 to 0.00035, saving model to model_inder_rnn2\n",
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_inder_rnn2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "6/6 [==============================] - 3s 546ms/step - loss: 2.5850e-04 - root_mean_squared_error: 0.0227 - mae: 0.0139 - val_loss: 3.4527e-04 - val_root_mean_squared_error: 0.0265 - val_mae: 0.0155 - lr: 0.0023\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, GRU, Input, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "\n",
    "# Define your learning rate scheduler function\n",
    "def lr_schedule(epoch):\n",
    "    initial_lr = 0.01\n",
    "    decay_factor = 0.9\n",
    "    return initial_lr * (decay_factor ** epoch)\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=10,          # Stop training after no improvement for 10 epochs\n",
    "    restore_best_weights=True,  # Restore the best weights when stopping\n",
    "min_delta=0.00001)\n",
    "\n",
    "# Create a model (you need to replace this with your actual model)\n",
    "model_1 = Sequential([\n",
    "    BatchNormalization(\n",
    "        input_shape = (window_size,num_features),\n",
    "        name = 'Batch_Norm_1'),\n",
    "    LSTM(512,return_sequences=True,name='LSTM_1'),\n",
    "#    BatchNormalization(),\n",
    "    LSTM(512,name='LSTM_2'),\n",
    "#    BatchNormalization(momentum=0.8),\n",
    "    Dense(256,activation='relu',name='Dense_1'),\n",
    "    Dense(len(tickers),name='Returns')\n",
    "])\n",
    "\n",
    "\n",
    "checkpont_rnn = ModelCheckpoint(\n",
    "    filepath='model_inder_rnn2',\n",
    "    save_weights_only=False,\n",
    "    save_freq = 'epoch',\n",
    "    monitor = 'val_loss',\n",
    "    save_best_only = True,\n",
    "    verbose = 1)\n",
    "\n",
    "# Compile the model with an optimizer (Adam in this example)\n",
    "optimizer = tf.keras.optimizers.Adam()  # Set initial learning rate to 0.0\n",
    "model_1.compile(\n",
    "    loss=tf.keras.losses.Huber(),\n",
    "    metrics=[tf.metrics.RootMeanSquaredError(),'mae'],\n",
    "    optimizer=optimizer)\n",
    "\n",
    "# Set up the learning rate scheduler callback\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# Initialize lists to store loss and learning rates\n",
    "losses = []\n",
    "learning_rates = []\n",
    "\n",
    "# Custom callback to log loss and learning rate\n",
    "class LossLearningRateCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.lr\n",
    "        loss = logs['loss']\n",
    "        learning_rates.append(lr)\n",
    "        print(learning_rates)\n",
    "        losses.append(loss)\n",
    "        print(f\"Epoch {epoch+1}: Learning Rate = {lr.numpy()}, Loss = {loss}\")\n",
    "\n",
    "\n",
    "# Create an instance of the custom callback\n",
    "loss_lr_callback = LossLearningRateCallback()\n",
    "\n",
    "# Train your model\n",
    "# history = model.fit(x_train, y_train, epochs=num_epochs, callbacks=[lr_scheduler, loss_lr_callback])\n",
    "history = model_1.fit(\n",
    "    my_window.train,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=my_window.val,\n",
    "    callbacks=[lr_scheduler, loss_lr_callback, early_stopping, checkpont_rnn]\n",
    ")\n",
    "\n",
    "# Access the losses from the training history\n",
    "losses = history.history['loss']\n",
    "learning_rates = [lr_schedule(epoch) for epoch in range(len(losses))]\n",
    "\n",
    "# Plot the loss and learning rate\n",
    "plt.plot(learning_rates, losses, marker='o')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs. Learning Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a307308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Batch_Norm_1 (BatchNormali  (None, 5, 86)             344       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " LSTM_1 (LSTM)               (None, 5, 512)            1226752   \n",
      "                                                                 \n",
      " LSTM_2 (LSTM)               (None, 512)               2099200   \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " Returns (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3460194 (13.20 MB)\n",
      "Trainable params: 3460022 (13.20 MB)\n",
      "Non-trainable params: 172 (688.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d468359e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model_1, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e376269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62da6487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d563c5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'RMSE Loss: Training and Validation')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training','Validation'])\n",
    "plt.title('Huber Loss: Training and Validation')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['root_mean_squared_error'])\n",
    "plt.plot(history.history['val_root_mean_squared_error'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training','Validation'])\n",
    "plt.title('RMSE Loss: Training and Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdd49756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************\n",
      "<_MapDataset element_spec=(TensorSpec(shape=(None, 5, 86), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 10), dtype=tf.float32, name=None))>\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.2639e-04 - root_mean_squared_error: 0.0213 - mae: 0.0145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00022639385133516043, 0.021278811618685722, 0.014514070004224777]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(my_window.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be053afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "# from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Create an example LSTM model\n",
    "\n",
    "\n",
    "# Plot the model architecture graph and save it to a file (e.g., model.png)\n",
    "plot_model(model_1, to_file='model_lstm.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0d57d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final learning rate used for the final model is: 2.9512665430652826e-07\n"
     ]
    }
   ],
   "source": [
    "final_learning_rate = lr_schedule(num_epochs - 1)\n",
    "print(f\"The final learning rate used for the final model is: {final_learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0408dc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.01,\n",
       "  0.009000000000000001,\n",
       "  0.008100000000000001,\n",
       "  0.007290000000000001,\n",
       "  0.006561,\n",
       "  0.005904900000000001,\n",
       "  0.00531441,\n",
       "  0.004782969000000001,\n",
       "  0.004304672100000001,\n",
       "  0.003874204890000001,\n",
       "  0.003486784401000001,\n",
       "  0.0031381059609000006,\n",
       "  0.0028242953648100013,\n",
       "  0.002541865828329001,\n",
       "  0.002287679245496101],\n",
       " [0.1254698634147644,\n",
       "  0.006389408838003874,\n",
       "  0.00042517148540355265,\n",
       "  0.00031286553712561727,\n",
       "  0.0002724082150962204,\n",
       "  0.0002632028190419078,\n",
       "  0.0002627891954034567,\n",
       "  0.00026186410104855895,\n",
       "  0.0002603436296340078,\n",
       "  0.00025929659022949636,\n",
       "  0.0002588236820884049,\n",
       "  0.00025855100830085576,\n",
       "  0.00025850211386568844,\n",
       "  0.0002585037727840245,\n",
       "  0.00025849658413790166])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d768b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
